{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dependências "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boosting** é uma abordadem de Machine Learning baseada na ideia de criar regras de predição com alta acurácia pela combinação de regras fracas e imprecisas. Boosting também é uma das abordages de aprendizagem supervisionada mais populares e bem sucedidas.\n",
    "\n",
    "O **Adaboost** é a técnica mais popular de boosting. A ideia básica do algoritmo é, para cada iteração, treinar um classificador fraco (accurácia > 50%) dando preferência (maiores pesos) aos exemplos incorretamente classificados pelo classificador anterior. Ao final, um classificador forte é construído pelo voto ponderado de cada um dos classificadores.\n",
    "\n",
    "**Vantagens:**\n",
    "- Fácil implementação\n",
    "- Rápido\n",
    "- Apenas um parâmetro para tunning (número de estimadores)\n",
    "- Pode ser usado como seletor de características\n",
    "- Boa generalização\n",
    "- Versátil\n",
    "\n",
    "**Desvantagens:**\n",
    "- Não é robusto a presença de ruído uniforme\n",
    "- Muitos classificadores fracos podem acarretar em overfitting\n",
    "\n",
    "\n",
    "__Pseudo-algoritmo__\n",
    "\n",
    "1. Para cada um dos n_estimadores:\n",
    "    - treine um classificador binário $C_i$ com $y \\in \\{-1, +1\\}$ de acordo com os pesos $w$\n",
    "    - Calcula as predições do classificador\n",
    "    - Calcule a taxa de erro ponderada \n",
    "    \n",
    "    $$e = w*1(y \\neq y_{pred}) = 1 - w*1(y=y_{pred}) \\tag{1}$$\n",
    "    \n",
    "    - Calcule os coeficientes \n",
    "    \n",
    "    $$\\alpha_i = 0.5 * \\log{\\frac{1-e}{e}} \\tag{2}$$\n",
    "    \n",
    "    - Atualize os pesos \n",
    "    \n",
    "    $$w = w*\\exp^{-\\alpha_i *y*y_{pred}} \\tag{3}$$\n",
    "    \n",
    "    - Normalize os pesos \n",
    "    \n",
    "    $$w = \\frac{w}{\\sum w} \\tag{4}$$\n",
    "\n",
    "O Classificador final será dado por:\n",
    "\n",
    "$$sign(\\sum_i{\\alpha_i*C_i.predict(x_{test})}) \\tag{5}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados são baseados na [aula sobre boosting](https://www.youtube.com/watch?v=u1MXf5N3wYU) do [curso de Machine Learning da Udacity](https://br.udacity.com/course/machine-learning--ud262). Eu tentei reproduzir, o mais fielmente possível, os dados do gráfico mostrado na aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([[1.0, 6.0],[1.5, 3.0],[3.2, 8.0],[5.2, 9.0],[7.0, 7.0],\n",
    "              [2.2, 2.0],[2.5, 6.5],[5.3, 5.5],[8.5, 8.5],[8.5, 3.2]])\n",
    "y = np.array([1, 1, 1, 1, 1, -1, -1, -1, -1, -1])\n",
    "\n",
    "plt.scatter(x[:5,0], x[:5,1], s=300, marker='+')\n",
    "plt.scatter(x[5:,0], x[5:,1], s=300, marker='_', color='red')\n",
    "plt.xlim(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(pred, y, weights):\n",
    "    return sum([w for p,t,w in zip(pred, y, weights) if p==t])/sum(weights)\n",
    "\n",
    "def sign(x):\n",
    "    if x == 0: return 0\n",
    "    return 1 if x > 0 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o Adaboost pode utilizar qualquer classificador como base, nós vamos implementar um classificador que só traça linhas em cada atributo (*feature*) tentando maximizar a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LineClassifier():\n",
    "    def __init__(self, weights=np.array([])):\n",
    "        self.weights = weights\n",
    "        self.value, self.col = 0, 0\n",
    "    \n",
    "    def fit(self, x, y):      \n",
    "        column_count = len(x[0])\n",
    "        \n",
    "        if len(self.weights) == 0:\n",
    "            self.weights = [1.0/len(x)]*len(x)\n",
    "        \n",
    "        best_accuracy = 0.0\n",
    "        \n",
    "        for col in range(column_count):\n",
    "            column_values = [row[col] for row in x]\n",
    "                \n",
    "            for value in np.arange(min(column_values), max(column_values), 0.1):\n",
    "                accuracy = weighted_accuracy(LineClassifier.predict_(x, col, value), y, self.weights)\n",
    "                \n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    self.col, self.value = col, value\n",
    "                    \n",
    "    def predict(self, x):\n",
    "        return LineClassifier.predict_(x, self.col, self.value)\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_(x, col, value):\n",
    "        if col == 0: \n",
    "            return [1 if row[col] < value else -1 for row in x]\n",
    "        else:\n",
    "            return [1 if row[col] > value else -1 for row in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, base_estimator=LineClassifier, minHitRate=0.5, n_estimators=50):\n",
    "        self.classifiers = []\n",
    "        self.alphas = []\n",
    "        self.weights = []\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.minHitRate = minHitRate\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        from math import log, e\n",
    "        ln = lambda x: log(x)/log(e)\n",
    "        \n",
    "        if len(self.weights) == 0:\n",
    "            self.weights = [1.0/len(x)]*len(x)\n",
    "        \n",
    "        for n in range(self.n_estimators):\n",
    "            clf = self.base_estimator()\n",
    "            clf.weights = self.weights\n",
    "            clf.fit(x, y)\n",
    "            \n",
    "            pred = clf.predict(x)\n",
    "            error = 1.0 - weighted_accuracy(pred, y, self.weights) # Eq. (1)\n",
    "            \n",
    "            if(error < self.minHitRate):\n",
    "                alpha = 0.5 * ln((1-error)/error) # Eq. (2)\n",
    "                \n",
    "                self.weights = [w*(e**(-alpha*p*t)) for p,t,w in zip(pred, y, self.weights)] # Eq. (3)\n",
    "                self.weights = [w/sum(self.weights) for w in self.weights] # Eq. (4)\n",
    "                \n",
    "                self.classifiers.append(clf)\n",
    "                self.alphas.append(alpha)\n",
    "                \n",
    "                print('[{}]: ε={:.2f} α={:.2f}'.format(n, error, alpha))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "\n",
    "        for row in x:\n",
    "            weak_sum = 0.0\n",
    "            \n",
    "            for alpha, clf in zip(self.alphas, self.classifiers):\n",
    "                weak_sum += alpha*clf.predict([row])[0] \n",
    "            predictions.append(sign(weak_sum)) # Eq. (5)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Teste "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gente pode conferir a implementação por esse [link](https://alliance.seas.upenn.edu/~cis520/wiki/index.php?n=lectures.boosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: ε=0.30 α=0.42\n",
      "[1]: ε=0.21 α=0.65\n",
      "[2]: ε=0.14 α=0.92\n",
      "y_true: [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n",
      "y_pred: [ 1  1  1  1  1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoost(base_estimator=LineClassifier, n_estimators=3, minHitRate=0.3)\n",
    "ada.fit(x, y)\n",
    "y_pred = ada.predict(x)\n",
    "\n",
    "print('y_true:', y)\n",
    "print('y_pred:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xv, yv = np.meshgrid(np.linspace(0, 10, 100), np.linspace(0, 10, 100))\n",
    "xyv = np.concatenate((xv, yv), axis=1)\n",
    "\n",
    "pred_2 = []\n",
    "for i in range(xv.shape[0]):\n",
    "    for j in range(xv.shape[1]):\n",
    "        pred_2.append(ada.predict([[xv[i,j], yv[i,j]]]))\n",
    "\n",
    "pred_2 = np.array(pred_2).reshape(xv.shape)\n",
    "plt.contourf(xv, yv, pred_2, cmap=plt.cm.Spectral, alpha=0.6)\n",
    "plt.scatter(x[:5,0], x[:5,1], s=300, marker='+')\n",
    "plt.scatter(x[5:,0], x[5:,1], s=300, marker='_', color='red')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Referências "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Machine Learning by Georgia Tech (Udacity)](https://br.udacity.com/course/machine-learning--ud262)\n",
    "- [Playlist about Adaboost on Youtube (same as above)](https://www.youtube.com/watch?v=w75WyRjRpAg)\n",
    "- [CIS 520 - Machine Learning 2018](https://alliance.seas.upenn.edu/~cis520/wiki/index.php?n=lectures.boosting)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
