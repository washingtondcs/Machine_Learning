{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "concrete = fetch_openml(data_id='4353',as_frame=True)\n",
    "X = concrete.data.iloc[:,0:8]\n",
    "y = concrete.data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                      540.0   \n",
       "1                                      540.0   \n",
       "2                                      332.5   \n",
       "3                                      332.5   \n",
       "4                                      198.6   \n",
       "\n",
       "   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                              142.5       \n",
       "3                                              142.5       \n",
       "4                                              132.4       \n",
       "\n",
       "   Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                      162.0   \n",
       "1                                      162.0   \n",
       "2                                      228.0   \n",
       "3                                      228.0   \n",
       "4                                      192.0   \n",
       "\n",
       "   Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                2.5     \n",
       "1                                                2.5     \n",
       "2                                                0.0     \n",
       "3                                                0.0     \n",
       "4                                                0.0     \n",
       "\n",
       "   Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                             1040.0      \n",
       "1                                             1055.0      \n",
       "2                                              932.0      \n",
       "3                                              932.0      \n",
       "4                                              978.4      \n",
       "\n",
       "   Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \n",
       "0                                              676.0       28.0  \n",
       "1                                              676.0       28.0  \n",
       "2                                              594.0      270.0  \n",
       "3                                              594.0      365.0  \n",
       "4                                              825.5      360.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Concrete compressive strength(MPa. megapascals), dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DivisÃ£o de treino e teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_min_max():\n",
    " def __init__(self):\n",
    "  self.max = None\n",
    "  self.min = None \n",
    "    \n",
    " def fit(self, data):\n",
    "  self.max = data.max()\n",
    "  self.min = data.min()\n",
    "    \n",
    " def transform(self, data):\n",
    "  return (data - self.min)/ (self.max-self.min)\n",
    "\n",
    " def inversa(self, data):\n",
    "  return data * (self.max - self.min) + self.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_x = scale_min_max()\n",
    "scale_y = scale_min_max()\n",
    "\n",
    "scale_x.fit(x_train)\n",
    "scale_y.fit(y_train)\n",
    "\n",
    "x_train_scaled = scale_x.transform(x_train)\n",
    "x_val_scaled = scale_x.transform(x_val)\n",
    "\n",
    "y_train_scaled = scale_y.transform(y_train)\n",
    "y_val_scaled = scale_y.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(u):\n",
    "    return np.maximum(0, u)\n",
    "\n",
    "def relu_dif(u):\n",
    "    return (u >= 0) * 1.0 \n",
    "\n",
    "def afim(z):\n",
    "    return z\n",
    "\n",
    "def afim_dif(z):\n",
    "    return np.ones(shape=z.shape) \n",
    "\n",
    "def tanh(u):\n",
    "    return (np.exp(2*u) - 1)/(np.exp(2*u) + 1)\n",
    "\n",
    "def tanh_dif(u):\n",
    "    return 1 - np.tanh(u)**2\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_dif(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=0)[None,:]\n",
    "\n",
    "def softmax_dif(z):\n",
    "    return softmax(z) * (1 - softmax(z))\n",
    "\n",
    "def cost_mse(true, pred):\n",
    "    return np.mean((true - pred)**2)\n",
    "\n",
    "def cost_logistic(true, pred):\n",
    "    return np.mean(- true * np.log(pred) - (1 - true) * np.log(1 - pred))\n",
    "\n",
    "def cost_softmax(true, pred):\n",
    "    return - np.sum(true * np.log(pred)) / len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(true, pred):\n",
    " rmse = np.sqrt(np.mean((true - pred)**2))\n",
    " return rmse\n",
    "\n",
    "def MSE(true, pred):\n",
    " mse = np.mean((true - pred)**2)\n",
    " return mse\n",
    "\n",
    "def MRE(y_true ,y_pred):\n",
    " mre = np.mean(np.abs((y_true - y_pred)/y_true))\n",
    " return mre\n",
    "\n",
    "def ACC(y_true, y_pred):\n",
    " acc = (y_true == y_pred).sum()/len(y_pred)\n",
    " return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuestÃ£o 1 (MLP para regressÃ£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MLP_1L():\n",
    "    \n",
    "    def __init__(self, Nh=20, momentum=0.9, t=300, rate=0.0001, \n",
    "                 size_batch= 32, phi_1 = 'tanh', phi_2 = 'afim', cost = 'mse', reg = 0.1):      \n",
    "        self.t = t\n",
    "        self.rate = rate\n",
    "        self.B = size_batch\n",
    "        self.lamb = reg\n",
    "                \n",
    "        self.W = None\n",
    "        self.M = None\n",
    "        self.D = None\n",
    "        self.Nh = Nh\n",
    "        self.momentum = momentum\n",
    "        self.K = 1\n",
    "        \n",
    "        self.atv_1 = phi_1\n",
    "        self.atv_2 = phi_2\n",
    "        self.phi_1 = None\n",
    "        self.phi_2 = None\n",
    "        self.cost = cost\n",
    "        self.f_cost = None\n",
    "        \n",
    "        self.costs = []\n",
    "        self.costs_val = []\n",
    "        \n",
    "        if self.atv_1 == 'tanh':\n",
    "            self.phi_1 = np.tanh               \n",
    "            self.phi_1_dif = tanh_dif\n",
    "            \n",
    "        if self.atv_1 == 'relu':\n",
    "            self.phi_1 = relu                \n",
    "            self.phi_1_dif = relu_dif                         \n",
    "                      \n",
    "        if self.atv_2 == 'afim':\n",
    "            self.phi_2 = afim          \n",
    "            self.phi_2_dif = afim_dif\n",
    "            self.f_cost = cost_mse\n",
    "            \n",
    "        if self.atv_2 == 'sigmoid':\n",
    "            self.phi_2 = sigmoid                \n",
    "            self.phi_2_dif = sigmoid_dif\n",
    "            self.f_cost = cost_logistic\n",
    "            \n",
    "        if self.atv_2 == 'softmax': \n",
    "            self.phi_2 = softmax                \n",
    "            self.phi_2_dif = softmax_dif\n",
    "            self.f_cost = cost_softmax          \n",
    "        \n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "        if self.atv_2 == 'softmax':\n",
    "            self.K = len(np.unique(y))\n",
    "        n = X.shape[0]\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        X_val = np.c_[np.ones(X_val.shape[0]), X_val]\n",
    "        y = y.reshape(-1,1) \n",
    "        y_val = y_val.reshape(-1,1)\n",
    "        self.D = X.shape[1]\n",
    "    \n",
    "        self.W = np.random.normal(loc= 0, scale=1,size=(self.Nh,self.D)) * np.sqrt(1/self.D)\n",
    "        self.W[:,0] = 0\n",
    "        self.M = np.random.normal(loc= 0, scale=1,size=(self.K, self.Nh+1)) * np.sqrt(1/self.Nh+1)\n",
    "        self.M[:, 0] = 0\n",
    "        W_past_increment = 0\n",
    "        M_past_increment = 0 \n",
    "                               \n",
    "        for epoch in range(self.t):\n",
    "            random_index = np.random.permutation(len(y))\n",
    "            X = X[random_index]\n",
    "            index = np.arange(0, n, self.B)\n",
    "            index[-1] = n\n",
    "            for i in range(len(index)-1):\n",
    "                start = index[i]\n",
    "                end = index[i+1]\n",
    "                X_batch = X[start:end, : ]\n",
    "                y_batch = y[start:end]\n",
    "                Z = np.zeros([len(X_batch), self.Nh+1])\n",
    "                \n",
    "                Z[:, 0] = 1                            \n",
    "                u = X_batch @ self.W.T\n",
    "                Z[:, 1:] = self.phi_1(u)\n",
    "                r = Z @ self.M.T\n",
    "                pred = self.phi_2(r)\n",
    "                \n",
    "                error = y_batch - pred\n",
    "                delta = error * self.phi_2_dif(r)              \n",
    "                zeta =  self.phi_1_dif(u) * (delta @ self.M[:, 1:])\n",
    "                term_M = self.lamb*self.M\n",
    "                term_M[:, 0] = 0\n",
    "                self.M = self.M + self.rate * (delta.T @ Z - term_M) +  self.momentum * M_past_increment\n",
    "                M_past_increment = self.rate * (delta.T @ Z - term_M)\n",
    "                term_W = self.lamb*self.W\n",
    "                term_W[:,0] = 0\n",
    "                self.W = self.W + self.rate * (zeta.T @ X_batch - term_W) + self.momentum * W_past_increment\n",
    "                W_past_increment = self.rate * (zeta.T @ X_batch - term_W)\n",
    "                \n",
    "                Z = np.zeros([len(X), self.Nh+1])\n",
    "                Z[:, 0] = 1                \n",
    "                u = X @ self.W.T\n",
    "                Z[:, 1:] = self.phi_1(u)\n",
    "                r = Z @ self.M.T\n",
    "                y_pred  = self.phi_2(r)                                 \n",
    "                loss = self.f_cost(y, y_pred)/2\n",
    "                self.costs.append(loss)\n",
    "                \n",
    "                Z = np.zeros([len(X_val), self.Nh+1])\n",
    "                Z[:, 0] = 1                \n",
    "                u = X_val @ self.W.T\n",
    "                Z[:, 1:] = self.phi_1(u)\n",
    "                r = Z @ self.M.T\n",
    "                y_pred_val  = self.phi_2(r)        \n",
    "                loss_val = self.f_cost(y_val, y_pred_val)/2\n",
    "                self.costs_val.append(loss_val)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \n",
    "        X = np.c_[np.ones(X.shape[0]), X]        \n",
    "        Z = np.zeros([len(X), self.Nh+1])\n",
    "        Z[:, 0] = 1                \n",
    "        u = X @ self.W.T\n",
    "        Z[:, 1:] = self.phi_1(u)\n",
    "        r = Z @ self.M.T\n",
    "        y_pred  = self.phi_2(r)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'Nh':[15 , 35 ,50,100],\n",
    "    'rate':[0.0001 ,0.00001],\n",
    "    'reg' : [0 ,0.01, 0.1, 0.25, 0.4]\n",
    "    }\n",
    "\n",
    "def RandomSearch(modelo, grid, qtd, cost):\n",
    "    combinations = []\n",
    "    while len(combinations) < qtd:\n",
    "        a = {}\n",
    "        for yi in grid.keys():\n",
    "            a[yi] = np.random.choice(grid[yi])\n",
    "            if a not in combinations:\n",
    "                combinations.append(a)\n",
    "                \n",
    "    scores = []      \n",
    "    for comb in combinations:\n",
    "        model = modelo(**comb)\n",
    "        model.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled)\n",
    "        y_pred = model.predict(x_val_scaled)\n",
    "        y_pred = scale_y.inversa(y_pred)\n",
    "        scores.append(cost(y_val, y_pred))\n",
    "        print(comb)\n",
    "        print(cost(y_val, y_pred))\n",
    "        print(\"----\")\n",
    "        \n",
    "    scores = np.array(scores)\n",
    "    best_index = np.argmin(scores)\n",
    "    best = combinations[best_index]\n",
    "        \n",
    "    return best, combinations, scores\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RamdomSearch usando o conjunto de validaÃ§Ã£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nh': 35, 'rate': 1e-05, 'reg': 0.1}\n",
      "17.504496983396084\n",
      "----\n",
      "{'Nh': 35, 'rate': 1e-05, 'reg': 0.01}\n",
      "17.449493964538206\n",
      "----\n",
      "{'Nh': 15, 'rate': 1e-05, 'reg': 0.0}\n",
      "20.705879986810004\n",
      "----\n",
      "{'Nh': 50, 'rate': 0.0001, 'reg': 0.1}\n",
      "16.901025273245647\n",
      "----\n",
      "{'Nh': 35, 'rate': 0.0001, 'reg': 0.1}\n",
      "17.024899899163703\n",
      "----\n",
      "{'Nh': 35, 'rate': 0.0001, 'reg': 0.4}\n",
      "16.904513950537257\n",
      "----\n",
      "{'Nh': 50, 'rate': 0.0001, 'reg': 0.01}\n",
      "16.957409477405587\n",
      "----\n",
      "{'Nh': 100, 'rate': 0.0001, 'reg': 0.25}\n",
      "16.88283231327997\n",
      "----\n",
      "{'Nh': 50, 'rate': 0.0001, 'reg': 0.25}\n",
      "16.91344941648791\n",
      "----\n",
      "{'Nh': 15, 'rate': 1e-05, 'reg': 0.4}\n",
      "18.619448002561032\n",
      "----\n",
      "{'Nh': 100, 'rate': 0.0001, 'reg': 0.4}\n",
      "16.87802096755491\n",
      "----\n",
      "{'Nh': 50, 'rate': 0.0001, 'reg': 0.1}\n",
      "16.977729568113176\n",
      "----\n",
      "{'Nh': 35, 'rate': 1e-05, 'reg': 0.01}\n",
      "19.657330385032484\n",
      "----\n",
      "{'Nh': 15, 'rate': 0.0001, 'reg': 0.25}\n",
      "16.86973009910636\n",
      "----\n",
      "{'Nh': 15, 'rate': 0.0001, 'reg': 0.25}\n",
      "16.952829293948962\n",
      "----\n",
      "{'Nh': 15, 'rate': 0.0001, 'reg': 0.4}\n",
      "16.84908659327432\n",
      "----\n",
      "{'Nh': 50, 'rate': 0.0001, 'reg': 0.4}\n",
      "16.897915761233154\n",
      "----\n",
      "{'Nh': 100, 'rate': 1e-05, 'reg': 0.1}\n",
      "17.605149732288492\n",
      "----\n",
      "{'Nh': 100, 'rate': 0.0001, 'reg': 0.0}\n",
      "16.92115919247063\n",
      "----\n",
      "{'Nh': 100, 'rate': 0.0001, 'reg': 0.0}\n",
      "17.0191893060685\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "best, combinations, scores = RandomSearch(MLP_1L, grid, 20, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nh': 15, 'rate': 0.0001, 'reg': 0.4}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance para o conjunto de validaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRE: 0.6085982970956474\n",
      "RMSE: 16.82599733466566\n"
     ]
    }
   ],
   "source": [
    "model = MLP_1L(**best)\n",
    "\n",
    "model.fit(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled)\n",
    "y_pred = model.predict(x_val_scaled)\n",
    "y_pred = scale_y.inversa(y_pred)\n",
    "\n",
    "\n",
    "mre = MRE(y_val, y_pred)\n",
    "RMSE = np.sqrt(MSE(y_val, y_pred))\n",
    "\n",
    "print(\"MRE: {}\".format(mre))\n",
    "print(\"RMSE: {}\".format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Curva de aprendizagem para treino e validaÃ§Ã£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x175891e4310>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo8ElEQVR4nO3de5wcZZ3v8c+vLzOTyXWSDAhJJFGjBAKSMAY8iOCiboCVi4oE4Ui85YgieNRdg/pCltU96rqIvg6Lgot4gxhxkawbjIrhuChgJggxIQRCAJMAYRKSQMhlprt/5496ZlLdVM90kp7M1PB9v16d1OXpqt9TXfPrp5+6mbsjIiLplxnoAEREpD6U0EVEhggldBGRIUIJXURkiFBCFxEZIpTQRUSGCCX0IcDMJpuZm1luoGOpJzOba2b3xMZ3mNlrBjKmwcbMXh22S3agY6lmXz7HyrL7sa47zezi/X1/2imh98LM3m9m7WEHfCbsLG8Z6Lheqdx9hLuvG+g4DpSZXRj2qR1mtsvMSrHxHfuyLHf/a9guxX6Md4KZFczstQnzbjezb+zL8ur1OZrZVWb244pln+7uPzjQZaeVEnoVZvZp4Frgn4FDgVcD/wacvR/LGlIt52peKfU8UO7+k5DURgCnA093j4dpPQZDy9vdNwJ3Af8zPt3MxgJnAK/YBDrouLteFS9gNLADOK+XMjcDX46NnwpsiI0/CXwOWAHsCcO3VSzjW8C3w/AHgdXAi8A64H/1su4s8A1gcyj7CcCBXCz+fweeATYCXwayVZY1C7gX2BbK/1+gITbfgcvCejYD/wJkwry5wB+AbwJbwnoaQ2x/BTYB3wGGxbcR8BngubC+D8bWNQ5YBLwA/An4J+CeilheBxwePp/u185oV3aA1wK/C/FsBn4CjIktYybw57Cdfwb8tOJz/DvgwbA9/ggcW/GZ/n34TF8K2/hQ4M6wvN8CLfu4r1XuNzcD1wOLwzreDpwZYn4BWA9cFSs/ueKzvztstz+EmH4NjK+y7s8B98feewmwCmhKKPt+4PGKaR8H/hyG5wOPh3U+DJwbKzc36XOs8TP/VqjzC8By4OQwfTbQCXSFfeChWP0/EoYzwBeBp4j2tx8Coyu228VE++pm4AsDnXsO9DXgAQzGV9hZCt07epUyN9N3Qn8QmAQMA44gSjwjw/wsUUI7MYyfSZSMDDgllJ1ZZd0fAx4Jyx4LLK34o74d+C4wHDgk/KEkfkEAxwMnArmwk68GPhWb72H5Y4l+pTwa+4OZG7bTJ8P7hxEl90Wh/EjgP4H/E9tGBeBqIE/UuttJSILAAmBhiHs60ZdRYiKoqMNPgFvD8OuAdxB9sbQCvweuDfMawh/35WH97yZKCl8O82eEP/wTwudzcfgcG2Of6X1ESXxCKPtAeF8T0RfJl2JxrQDe38e+diovT+jbgZOIElJTKHNMGD+W6IvynFB+Mi9P6I8Drw+fx93AV6usOxO2z1XAVGArMKNK2WEhrrfEpt3bva8A5xF90WaA84m+jA6L7SfVEnpfn/lFREk/R9QQeJbwhRPi/nFFnHezd//8ELAWeA0wAvgP4EcV2+3GULc3EjW8pg10/jmg3DXQAQzGF3Ah8GwfZW6m74T+oYr33AN8IAy/g4oWT0XZXwCXV5n3O+BjsfF3dv9REyWbPYRWcZh/AbC0xrp/Crg9Nu7A7Nj4x4G7wvBc4K+xeRb+kF8bm/Zm4InYNtpF7IuSKCmeSJRAu4AjY/P+uVoiiE37HFHLbViV+pzD3lbkW0PCsIrPpDuhXw/8U8X71wCnxD7TC2Pzfg5cHxv/JPCLfdzXKvebm4Ef9vGea4FvhuHuxBRP6F+s+Lx+1cuyJgPPE32RX9HHer8H3BCGpxJ9GR5SpeyDwNmx/STpl1afn3nCcrcCbwzDV9F7Qr8L+Hhs3hvC+robLw5MjM3/EzBnXz6/wfZSH3qyLcD4OvQJr68Yv4UouUL0E/aW7hlmdrqZ3Wdmz5vZNqLW6/gqyz28YtlPxYaPIGp9PmNm28KyvkvUUn8ZM3u9mf3SzJ41sxeI/qAq11u5rsOrzGsFmoHlsXX/KkzvtsXdC7HxnUStp1aiP7Rq9UqK/XSi1vY57r4rTDvUzBaY2cZQnx/H6nM4sNHDX29C/EcAn+mOPcQ/qaK+m2LDuxLGy/rA91PZfmNmJ5jZUjPrMLPtRL/Qqu0bELViu3Vv30Tu/iTRL7DJwHV9xPUD4DwzayLqT1/i7s+FGD9gZg/Gttv0PmKEGj5zM/usma02s+1huaNrWG63wyuW9xR7Gz3dat5WaaCEnuxeolbuOb2UeYkoeXV7VUIZrxj/GXCqmU0EziUkdDNrJGrtfQM41N3HEPWhWpV1P0OUaLq9Oja8PsQ+3t3HhNcodz+6yrKuJ+q+meruo4DPJ6y3cl1PV6njZqKkdnRs3aO94kBfFR1E3THV6lXGzN5AlGDe5+7xhPDPIaZjQn0uitXnGWCCmcXrF1/feuArsdjHuHuzu99aQ/z1VLnf3ELUjTXJ3UcTHZeotm/sEzM7k+hX1F1Ex0d6cw9Ra/5sou36g7CMI4i6Li4FxoX9d2UNMfb6mZvZycA/AO8j6pYbQ9Tt073cyu1U6WmiL+n4sguUfwkPKUroCdx9O3AlcJ2ZnWNmzWaWD63or4diDwJnmNlYM3sVUVdFX8vtIPpJ+H2ibojVYVYDUZ9vB1AILc939rKohcBlZjbRzFqIDkh1r+MZogNh/2pmo8wsY2avNbNTqixrJNEBpx1mdiTRgbFKf29mLWY2iahF/NMq9SsR/WF/08wOgZ5T3v62l7p0v7dI1Md5VdjeRxH1Yb+MmY0C7iA6iFV5zvJIooNk281sAtFBzG73AkXgUjPLmdnZRAeFu90IfCy0iM3MhpvZmWY2sq/4+9lI4Hl3321ms4h+3R0wMxtP1I3yEaJt/S4zO6Na+fDL5ofA14AxRMdHIOr/dqL9FzP7IFELvVc1fOYjiRJwB5AzsyuBUbH5m4DJZlYtj90K/G8zm2JmI4i+7H9a8QtxSFFCr8Ld/xX4NNFR8g6i1tulRH3bAD8CHiLqV/01VZJcgluIzlzo6W5x9xeJziRZSNRH+H6iFlk1NwJLwvofIPqjiPsA0ZfEw2F5twGHVVnWZ8P6XgzLTarHHUT91A8C/0V0dkc1nyM6EHVf6PL4LVHfZS0uJfrJ+yxRX/L3q5SbGZb5zYTzt/8xzN8eYu3ZNu7eSXQg9MNEZ7FcBPyS6BcN7t4OfJToTJ+toR5za4z9ZcxslZlduL/vj/k4cLWZvUjU0FhYh2UC3ADc4e6L3X0L0Xb5npmN6+U9PyRq6f7U3bu328PAvxJ9YW4iOoD7hxpj6O0zX0LUZfcoUXfJbsq7Z34W/t9iZg8kLPsmor/T3wNPhPd/ssa4UsnKuxNFypmZE3XHrB3oWPqDmd0PfMfdq315iKSGWujyimJmp5jZq0KXy8VEpwH+aqDjEqkHXdknrzRvYO95z+uA94bjDiKppy4XEZEhQl0uIiJDxIB1uYwfP94nT548UKsXEUml5cuXb3b31qR5A5bQJ0+eTHt7+0CtXkQklcys6hXU6nIRERkilNBFRIYIJXQRkSFC56GLSF10dXWxYcMGdu/ePdChDAlNTU1MnDiRfD5f83uU0EWkLjZs2MDIkSOZPHky5Te0lH3l7mzZsoUNGzYwZcqUmt9XU5eLmc02szVmttbM5ifMf3W4X/OfzWxFb3dsE5Ghaffu3YwbN07JvA7MjHHjxu3zr50+E3p4SO11RA+zPQq4INzmMu6LwEJ3nwHMIXqYsoi8wiiZ18/+bMtaWuizgLXuvi7cfnQB0Q3u45y99ykeTfkDEOpq2ZPPc82v19BZKPXXKkREUqmWhD6B8nsQbwjT4q4CLjKzDURP2km857CZzTOzdjNr7+jo2I9wYc2aR7h36S8pFLr26/0iMjRt27aNf/u3fe8cOOOMM9i2bVv9AxoA9Tpt8QLgZnefSPQszB8lPUXE3W9w9zZ3b2ttTbxytU+ve+5X/KzxaijoSLqI7FUtoRcKvT+gaPHixYwZM6afojq4ajnLZSPlz/ybGKbFfRiYDeDu94aHyI4neqJ7v9BNIkUkbv78+Tz++OMcd9xx5PN5mpqaaGlp4ZFHHuHRRx/lnHPOYf369ezevZvLL7+cefPmAXtvQ7Jjxw5OP/103vKWt/DHP/6RCRMmcMcddzBs2LABrlntaknoy4CpZjaFKJHP4eXPNPwrcBpws5lNA5oIzxfsP8roIoPVP/7nKh5++oW6LvOow0fxpXdVe9Y5fPWrX2XlypU8+OCD3H333Zx55pmsXLmy57S/m266ibFjx7Jr1y7e9KY38Z73vIdx48qftvfYY49x6623cuONN/K+972Pn//851x00UV1rUd/6jOhu3vBzC4ler5fFrjJ3VeZ2dVAu7svAj4D3Ghm/5so0871/rrRuo6ii0gNZs2aVXYO97e//W1uv/12ANavX89jjz32soQ+ZcoUjjvuOACOP/54nnzyyYMVbl3UdGGRuy8mOtgZn3ZlbPhh4KT6htZHTAdzZSKyT3prSR8sw4cP7xm+++67+e1vf8u9995Lc3Mzp556auI53o2NjT3D2WyWXbt2HZRY6yWF93IJLXR1ootIzMiRI3nxxRcT523fvp2Wlhaam5t55JFHuO+++w5ydAeHLv0XkSFh3LhxnHTSSUyfPp1hw4Zx6KGH9sybPXs23/nOd5g2bRpveMMbOPHEEwcw0v6T2oSuZ6GKSKVbbrklcXpjYyN33nln4rzufvLx48ezcuXKnumf/exn6x5ff0tdl4sOiYqIJEtdQhcRkWSpS+iu0xZFRBKlLqF3Uw+6iEi51CZ0nbYoIlIuhQldXS4iIklSmNAjap+LyIEYMWIEAE8//TTvfe97E8uceuqptLe397qca6+9lp07d/aMD+TteFOb0NXlIiL1cPjhh3Pbbbft9/srE/pA3o43fQldZ7mISIL58+dz3XXX9YxfddVVfPnLX+a0005j5syZHHPMMdxxxx0ve9+TTz7J9OnTAdi1axdz5sxh2rRpnHvuuWX3crnkkktoa2vj6KOP5ktf+hIQ3fDr6aef5m1vextve9vbgOh2vJs3bwbgmmuuYfr06UyfPp1rr722Z33Tpk3jox/9KEcffTTvfOc763bPmNReKao+F5FB7M758Oxf6rvMVx0Dp3+16uzzzz+fT33qU3ziE58AYOHChSxZsoTLLruMUaNGsXnzZk488UTOOuusqs/rvP7662lubmb16tWsWLGCmTNn9sz7yle+wtixYykWi5x22mmsWLGCyy67jGuuuYalS5cyfvz4smUtX76c73//+9x///24OyeccAKnnHIKLS0t/Xab3vS10Hsoo4vIXjNmzOC5557j6aef5qGHHqKlpYVXvepVfP7zn+fYY4/l7W9/Oxs3bmTTpk1Vl/H73/++J7Eee+yxHHvssT3zFi5cyMyZM5kxYwarVq3i4Ycf7jWee+65h3PPPZfhw4czYsQI3v3ud/Pf//3fQP/dpjeFLXR1uYgMer20pPvTeeedx2233cazzz7L+eefz09+8hM6OjpYvnw5+XyeyZMnJ942ty9PPPEE3/jGN1i2bBktLS3MnTt3v5bTrb9u06sWuogMGeeffz4LFizgtttu47zzzmP79u0ccsgh5PN5li5dylNPPdXr+9/61rf23OBr5cqVrFixAoAXXniB4cOHM3r0aDZt2lR2o69qt+09+eST+cUvfsHOnTt56aWXuP322zn55JPrWNuXq6mFbmazgW8RPbHoe+7+1Yr53wTeFkabgUPcfUwd44ytKwzoLBcRqXD00Ufz4osvMmHCBA477DAuvPBC3vWud3HMMcfQ1tbGkUce2ev7L7nkEj74wQ8ybdo0pk2bxvHHHw/AG9/4RmbMmMGRRx7JpEmTOOmkvc/zmTdvHrNnz+bwww9n6dKlPdNnzpzJ3LlzmTVrFgAf+chHmDFjRr8+Bcn6ug2tmWWBR4F3ABuInjF6QXhKUVL5TwIz3P1DvS23ra3N+zq/M8l9t36FE9d8ne2ffJTR4w7t+w0iclCsXr2aadOmDXQYQ0rSNjWz5e7ellS+li6XWcBad1/n7p3AAuDsXspfANxaY7z7TQ10EZFytST0CcD62PiGMO1lzOwIYArwuyrz55lZu5m1d3R07Gus0TJ6hpTRRUTi6n1QdA5wm7sXk2a6+w3u3ububa2trfu1AtdZLiKDlp4kVj/7sy1rSegbgUmx8YlhWpI5HITuFlD7XGSwaWpqYsuWLUrqdeDubNmyhaampn16Xy1nuSwDpprZFKJEPgd4f2UhMzsSaAHu3acI9pHOchEZnCZOnMiGDRvY3+5UKdfU1MTEiRP36T19JnR3L5jZpcASotMWb3L3VWZ2NdDu7otC0TnAAu/3r2d1uYgMRvl8nilTpgx0GK9oNZ2H7u6LgcUV066sGL+qfmHVFNPBXJ2IyKCnK0VFRIaI9CV03T5XRCRR+hK6iIgkSm1CV4eLiEi51CZ0nbYoIlIuhQldfegiIklSmNAjap+LiJRLX0LXlaIiIonSl9DV5SIikiiFCT3i6nQRESmT2oSudrqISLkUJnSlchGRJClM6IF6XEREyqQuoet+6CIiyVKX0PUIOhGRZKlL6N3UPhcRKZe6hL63fa6ULiISV1NCN7PZZrbGzNaa2fwqZd5nZg+b2Sozu6W+Ye6lLhcRkWR9PoLOzLLAdcA7gA3AMjNb5O4Px8pMBa4ATnL3rWZ2SH8F3E3HREVEytXSQp8FrHX3de7eCSwAzq4o81HgOnffCuDuz9U3zL32PrBIGV1EJK6WhD4BWB8b3xCmxb0eeL2Z/cHM7jOz2UkLMrN5ZtZuZu0dHR37F7G6XEREEtXroGgOmAqcClwA3GhmYyoLufsN7t7m7m2tra0HtELdy0VEpFwtCX0jMCk2PjFMi9sALHL3Lnd/AniUKMH3H3Wii4iUqSWhLwOmmtkUM2sA5gCLKsr8gqh1jpmNJ+qCWVe/MGNMXS4iIkn6TOjuXgAuBZYAq4GF7r7KzK42s7NCsSXAFjN7GFgK/L27b+mvoEVE5OX6PG0RwN0XA4srpl0ZG3bg0+F1ULi6XEREyqTuSlGd5SIikiyFCV1ERJKkN6Gry0VEpEzqErrpLBcRkUSpS+giIpIstQldZ7mIiJRLbULXzblERMqlLqG7+tBFRBKlLqF3U4+LiEi51CV0tc9FRJKlLqHrEXQiIslSl9BFRCRZ6hJ6zzFRdaKLiJRJXUJXL7qISLIUJvSIGugiIuVSm9B1YZGISLmaErqZzTazNWa21szmJ8yfa2YdZvZgeH2k/qH2rK3/Fi0ikmJ9PrHIzLLAdcA7iB4GvczMFrn7wxVFf+rul/ZDjFWohS4iEldLC30WsNbd17l7J7AAOLt/w6qFErqISFwtCX0CsD42viFMq/QeM1thZreZ2aSkBZnZPDNrN7P2jo6O/QiX2HmLIiISV6+Dov8JTHb3Y4HfAD9IKuTuN7h7m7u3tba21mnVIiICtSX0jUC8xT0xTOvh7lvcfU8Y/R5wfH3Cq85L6nIREYmrJaEvA6aa2RQzawDmAIviBczssNjoWcDq+oVYTo+gExFJ1udZLu5eMLNLgSVAFrjJ3VeZ2dVAu7svAi4zs7OAAvA8MLcfYxYRkQR9JnQAd18MLK6YdmVs+ArgivqG1kdMOstFRKRMCq8UVZeLiEiSFCZ0ERFJkt6E7qWBjkBEZFBJX0LXWS4iIonSl9BFRCRRahO664boIiJl0pfQ1eUiIpIofQldREQSpTahq8dFRKRc6hK66cIiEZFEqUvornwuIpIodQl9L/W5iIjEpS6h9zTQ1YkuIlImdQldN+cSEUmWwoQuIiJJ0pvQ1eUiIlImfQldV4qKiCSqKaGb2WwzW2Nma81sfi/l3mNmbmZt9QtRRERq0WdCN7MscB1wOnAUcIGZHZVQbiRwOXB/vYNMokfQiYiUq6WFPgtY6+7r3L0TWACcnVDun4CvAbvrGF+C9PUSiYgcDLVkxwnA+tj4hjCth5nNBCa5+3/1tiAzm2dm7WbW3tHRsc/BiohIdQfc3DWzDHAN8Jm+yrr7De7e5u5tra2tB7Re3Q9dRKRcLQl9IzApNj4xTOs2EpgO3G1mTwInAov668CoTnIREUlWS0JfBkw1sylm1gDMARZ1z3T37e4+3t0nu/tk4D7gLHdv75eIRUQkUZ8J3d0LwKXAEmA1sNDdV5nZ1WZ2Vn8HWD2w0oCtWkRkMMrVUsjdFwOLK6ZdWaXsqQceVi/U5yIikkjnAIqIDBGpTeg6yUVEpFzqErqpy0VEJFHqErqIiCRLbULXhUUiIuVSl9A9fSGLiBwUyo4iIkNEehO6LiwSESmTuoSus1xERJKlLqGLiEgyJXQRkSEitQldpy2KiJRLbUIXEZFySugiIkNEihO6ulxEROJSl9CjR5iKiEilmrKjmc02szVmttbM5ifM/5iZ/cXMHjSze8zsqPqHKiIivekzoZtZFrgOOB04CrggIWHf4u7HuPtxwNeBa+odaCWd5SIiUq6WFvosYK27r3P3TmABcHa8gLu/EBsdTn92cOtKURGRRLU8U3QCsD42vgE4obKQmX0C+DTQAPxNXaITEZGa1e0Io7tf5+6vBT4HfDGpjJnNM7N2M2vv6Og40BUe2PtFRIaYWhL6RmBSbHximFbNAuCcpBnufoO7t7l7W2tra81BllGXi4hIoloS+jJgqplNMbMGYA6wKF7AzKbGRs8EHqtfiCIiUos++9DdvWBmlwJLgCxwk7uvMrOrgXZ3XwRcamZvB7qArcDF/Rl0iKu/VyEikiq1HBTF3RcDiyumXRkbvrzOcVWlHhcRkWS67FJEZIhIcUJXl4uISFwKE3oKQxYROQiUHUVEhojUJnQvlQY6BBGRQSV9CV2nuYiIJEpfQhcRkUQpTug6y0VEJC6FCT3qclE6FxEpl7qErh50EZFkqUvo3UxtdBGRMqlL6B7OctG9uUREyqUuoavLRUQkWeoSuoiIJEtvQlefi4hImdQldNOVoiIiiVKX0EVEJFlNCd3MZpvZGjNba2bzE+Z/2sweNrMVZnaXmR1R/1ArqMtFRKRMnwndzLLAdcDpwFHABWZ2VEWxPwNt7n4scBvw9XoHGguo3xYtIpJmtbTQZwFr3X2du3cCC4Cz4wXcfam77wyj9wET6xumiIj0pZaEPgFYHxvfEKZV82HgzqQZZjbPzNrNrL2jo6P2KBO4rhQVESlT14OiZnYR0Ab8S9J8d7/B3dvcva21tXU/16LjuCIiSXI1lNkITIqNTwzTypjZ24EvAKe4+576hCciIrWqpbm7DJhqZlPMrAGYAyyKFzCzGcB3gbPc/bn6h/lyrrNcRETK9JnQ3b0AXAosAVYDC919lZldbWZnhWL/AowAfmZmD5rZoiqLO2A6yUVEJFktXS64+2JgccW0K2PDb69zXCIiso/Se4RRXS4iImXSl9DV5yIikih9CV1ERBKlN6Gry0VEpEwKE3p4BN0ARyEiMtikL6GrC11EJFH6EnpgaqOLiJRJYUIPXS7K5yIiZVKX0E19LiIiiVKX0PdSE11EJC59Cd26z3JRQhcRiUtfQhcRkUTpTeg6KioiUiZ9CT10uZgSuohImdQldMtkAT3gQkSkUuoSeiYTheyl4gBHIiIyuKQuoWMhoXtpgAMRERlcakroZjbbzNaY2Vozm58w/61m9oCZFczsvfUPM7au0OWCErqISJk+E7qZZYHrgNOBo4ALzOyoimJ/BeYCt9Q7wEp7u1yU0EVE4mp5pugsYK27rwMwswXA2cDD3QXc/ckwr9+zrKnLRUQkUS1dLhOA9bHxDWHaPjOzeWbWbmbtHR0d+7MI0EFREZFEB/WgqLvf4O5t7t7W2tq6X8vI9PShK6GLiMTVktA3ApNi4xPDtAERdenrPHQRkUq1JPRlwFQzm2JmDcAcYFH/hlWdhS4X1OUiIlKmz4Tu7gXgUmAJsBpY6O6rzOxqMzsLwMzeZGYbgPOA75rZqv4KuDuhq4UuIlKulrNccPfFwOKKaVfGhpcRdcX0u56zXNRCFxEpk7orRTO6sEhEJFH6Eno2HBTVhUUiImVSl9At3D5Xpy2KiJRLX0LPhm5/dbmIiJRJXULP9JyHroQuIhKXuoRumdDloj50EZEy6UvouSYAMqXOAY5ERGRwSV1CzzePpuhGdvfWgQ5FRGRQqenCosFk5LAGtjKCo/96C9wzCYa3QtMoGDYWmsfCsJbolWsE956HSouIDHWpS+iZjHGXvZmz/f/Bb79UtZxncpBtwEceRqZpVJTkRxwKDSOgcWSU/PPDID88+r9hODSOioabx0K+OfpSyDVB98VMIiKDWOoSOsDNLZfxD8/MZQQ7+R+HQeeObRRf2kJrbieH5XeS3b2VYzJP8ObiKlZ0NDKpYTMtPEFDPoeVush3bt+n9XkmH/Xd5xop5RopZhqxXCOdNNDUPJxMvilK/N1fAGX/D6syvQnyTXvnhy8gsg3Rrwqz6Msm1xDNs2z0xZLJ6QtGRBKlMqH/+CMncNmtf+aetZv59TNw2pGTGd2UY9OOPWwoOGs7dtBVLPHi7gJvnDSGJzp28MLuQs/7M5RoZjfD6OTo1jxj8p1sfGYTzbaHkexkuO2miU5aGkoUO3fRaF0MLxRoznRhhT00WheNdNFIJ8Oz22lt2k6TdZItdUJhN5liJ03WRYN30kD9D96WLAuWpWQZIEMmm8OzDZQwipanBJQyjTQ05CmVnKLlyGSzZDI5MIsuzsrkIZOh5FB0o7kxj4fldZacrpLhRGWz2WxPGctkKZRgT9EZ3tRAZ9FxMhSx6D47lgnlYXcB8rkMjfk8DbkslsniGCWMTCYb3WjNsnR61C2Wy0TrbshmMYNdXU6+oQHzEpbJkjELN2ez6GHhFv7HeoaLTigLL+4pkDenId9AMdzLLZ/LAY57CbMspXD6ayaT7XkAOaEePXf07Om2M9wylCxD1vaW6yo6hVKJYQ350M2XSf7S9VL0hYwBvrcO3bO7ewi71989MS4WS9VpZd2MYTgeT882iw1XriO+3qrL389xL3VXFPDymBJ1x2L934XaE1dv88sm9FGmImZ3wKMeg8aR+x9ntfAG6q6FbW1t3t7efkDL2PpSJw25DMMb+/5eWv7UVl7aU+CRZ1/g+rsfJ5sxDh3VRGMuw+6uEuNGNJAxY/yIRnYXioweluexTS+yfVcXE1uaOWx0E7mMMWpYnv94ILod/J5CkYktzTz/UmdPLA6MbMrRmMvw6KYdgDOmocShw4yc72H7iztopJNGumiik2G2hwYK5CmQo0iOIhmcnBVpopMGCmQohekl8hTJW4EsJTKUorIUaaCAUaLBihglGsP7APLhvd3vAchRxIBMeGpg97IyIeV2D0fj0au7THw4g2PWPa2XMmX/l3rG86YrfuWV54FjrmTmez6zX+81s+Xu3pY4L80JfbDb3VVkx54C44Y39NyyoLNQ4ultu+gsltiwdSfTDx8NBn9cu4XDRjfxxkljKJacYfksTz2/k2e27aK5MUdTPsOTm19iVFOeksO2XZ2MbMqzfVcXuzuLmMGY5gbGNOcZls/ywF+30pjL0NLcwPDGHM+/1ElnoUTRHXenWIKSO7mMsW7zSzTlMnQWneaGLK0jGxkzLE8um2HTC7vpKpYY1ZRn04u72fpSJyWHxlyGfDZDS3PU+s5ljVLJKZSczkIJB1pHNtJVKLF1Zyfbdnaxs7OI44welqezUKJQcrxUYkxzA2bOnq4iDdmoZV0qOGNH5KBYwDF27umiY8duRjRkac5nKBRL0cVlHn1BZA2y5jTlMhSLBTBjeEOWkhu7O7tobshgwAu79lAowvCmPHs6uyiUYFhDJrods3e33B1zx816GofFktNVKJG3aL3FktOUM3IZwJ1c1ujsKpLLZshaiVIxqt+wfIaukrOzs0A2kyFvHr0Ho1gskM3EW3POzs4ijdno9LNdXUWyGSOXzWAYZk6xGH1mZrCrs0g2A9mM4e5kLHpf0Z1SqE8uk4mmezH67DEas5A16CwUKRSKYFAolqJ1ZYxsximUoFCMlpHJZMh1N64pUSpFt68uhS/oplyWrmKRUgnyWchmMljYcEbUQO0sFOgqOA1Zix4jGfbDkkPJoSkX7Y8lJ9TFehq2XcUS2UyGYrFEPmtkM9EvR3en6FAqlii5k89lyJhR8mg7dH98xZJjFv0PkDEohh8J0eaP1mVAJsRdCnnRu/8J29Z73h/VPWvdNe0u5j3jOGE7hGV592TjdcefxoyZs/Yrryihi4gMEb0l9NSdhy4iIslqSuhmNtvM1pjZWjObnzC/0cx+Gubfb2aT6x6piIj0qs+EbtFTma8DTgeOAi4ws6Mqin0Y2OrurwO+CXyt3oGKiEjvammhzwLWuvs6d+8EFgBnV5Q5G/hBGL4NOM2sv88vEhGRuFoS+gRgfWx8Q5iWWCY8VHo7MK5yQWY2z8zazay9o6Nj/yIWEZFEB/WgqLvf4O5t7t7W2tp6MFctIjLk1ZLQNwKTYuMTw7TEMmaWA0YDW+oRoIiI1KaWhL4MmGpmU8ysAZgDLKooswi4OAy/F/idD9QJ7iIir1A1XVhkZmcA1wJZ4CZ3/4qZXQ20u/siM2sCfgTMAJ4H5rj7uj6W2QE8tZ9xjwc27+d7B7OhWK+hWCcYmvVSndLhCHdP7LMesCtFD4SZtVe7UirNhmK9hmKdYGjWS3VKP10pKiIyRCihi4gMEWlN6DcMdAD9ZCjWayjWCYZmvVSnlEtlH7qIiLxcWlvoIiJSQQldRGSISF1C7+tWvoOJmd1kZs+Z2crYtLFm9hszeyz83xKmm5l9O9RrhZnNjL3n4lD+MTO7OGldB4uZTTKzpWb2sJmtMrPLw/S016vJzP5kZg+Fev1jmD4l3BJ6bbhFdEOYXvWW0WZ2RZi+xsz+doCq1MPMsmb2ZzP7ZRgfCnV60sz+YmYPmll7mJbqfbAuPDwKKg0vogubHgdeAzQADwFHDXRcvcT7VmAmsDI27evA/DA8H/haGD4DuJPoSVgnAveH6WOBdeH/ljDcMoB1OgyYGYZHAo8S3VY57fUyYEQYzgP3h3gXEl0oB/Ad4JIw/HHgO2F4DvDTMHxU2C8bgSlhf80O8H74aeAW4JdhfCjU6UlgfMW0VO+DddkuAx3APn6IbwaWxMavAK4Y6Lj6iHlyRUJfAxwWhg8D1oTh7wIXVJYDLgC+G5teVm6gX8AdwDuGUr2AZuAB4ASiqwxzlfsfsAR4cxjOhXJWuU/Gyw1QXSYCdwF/A/wyxJjqOoUYkhL6kNkH9/eVti6XWm7lO9gd6u7PhOFngUPDcLW6Ddo6h5/kM4has6mvV+iaeBB4DvgNUUt0m0e3hIbyGKvdMnqw1eta4B+AUhgfR/rrBNGTl39tZsvNbF6Ylvp98EDlBjqAVzJ3dzNL5XmjZjYC+DnwKXd/wWLPM0lrvdy9CBxnZmOA24EjBzaiA2Nmfwc85+7LzezUAQ6n3t7i7hvN7BDgN2b2SHxmWvfBA5W2Fnott/Id7DaZ2WEA4f/nwvRqdRt0dTazPFEy/4m7/0eYnPp6dXP3bcBSou6IMRbdEhrKY6x2y+jBVK+TgLPM7EmiJ439DfAt0l0nANx9Y/j/OaIv31kMoX1wf6UtoddyK9/BLn6r4YuJ+qC7p38gHJE/Edgefj4uAd5pZi3hqP07w7QBYVFT/N+B1e5+TWxW2uvVGlrmmNkwouMCq4kS+3tDscp6Jd0yehEwJ5wxMgWYCvzpoFSigrtf4e4T3X0y0d/K79z9QlJcJwAzG25mI7uHifadlaR8H6yLge7E39cX0RHrR4n6N78w0PH0EeutwDNAF1H/3IeJ+iTvAh4DfguMDWWN6GHcjwN/Adpiy/kQsDa8PjjAdXoLUf/lCuDB8DpjCNTrWODPoV4rgSvD9NcQJa+1wM+AxjC9KYyvDfNfE1vWF0J91wCnD/R+GGI6lb1nuaS6TiH+h8JrVXceSPs+WI+XLv0XERki0tblIiIiVSihi4gMEUroIiJDhBK6iMgQoYQuIjJEKKGLiAwRSugiIkPE/wdmob5vBIOWbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.costs, label='train')\n",
    "plt.plot(model.costs_val, label='validation')\n",
    "plt.title(\"Curva de aprendizagem: Train x Validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance para o conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRE: 0.6063459973159556\n",
      "RMSE: 16.836396033461323\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_train_scaled)\n",
    "y_pred = scale_y.inversa(y_pred)\n",
    "\n",
    "\n",
    "mre = MRE(y_train, y_pred)\n",
    "RMSE = np.sqrt(MSE(y_train, y_pred))\n",
    "\n",
    "print(\"MRE: {}\".format(mre))\n",
    "print(\"RMSE: {}\".format(RMSE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo usando treino e validaÃ§Ã£o e avaliando no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_x.fit(x_train)\n",
    "scale_y.fit(y_train)\n",
    "\n",
    "x_train_scaled  = scale_x.transform(x_train)\n",
    "x_val_scaled = scale_x.transform(x_test)\n",
    "\n",
    "y_train_scaled = scale_y.transform(y_train)\n",
    "y_val_scaled = scale_y.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRE: 90.30078896061805\n",
      "RMSE: 2586.0937339909215\n"
     ]
    }
   ],
   "source": [
    "model = MLP_1L(**best)\n",
    "\n",
    "model.fit(x_train, y_train, x_val, y_val)\n",
    "y_pred = model.predict(x_val)\n",
    "y_pred = scale_y.inversa(y_pred)\n",
    "\n",
    "\n",
    "mre = MRE(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE(y_test, y_pred))\n",
    "\n",
    "print(\"MRE: {}\".format(mre))\n",
    "print(\"RMSE: {}\".format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuestÃ£o 2 (MLP para classificaÃ§Ã£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_vowel = np.genfromtxt('./Dados/vowel.csv', delimiter = ',', skip_header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_vowel = np.genfromtxt('./Dados/vowel.csv', delimiter = ',', skip_header = 0)\n",
    "np.set_printoptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados_vowel[:, 0:-1]\n",
    "y = dados_vowel[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y)) # nÃºmero de classes\n",
    "Y = np.zeros((y.shape[0], n_classes)) # inicializando a matriz Y com zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[0] # tamanho da amostra original\n",
    "D = X.shape[1] # nÃºmero de dimensÃµes de entrada (atributos)\n",
    "K = Y.shape[1] # nÃºmero de dimensÃµes de saÃ­da (classes)\n",
    "n_train = round(0.6*n) # tamanho da amostra de treino\n",
    "n_validacao = round(0.2*n) # tamanho da amostra de validaÃ§Ã£o\n",
    "n_teste = n - n_train - n_validacao # tamanho da amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_min_max(X, X_train): # normalizaÃ§Ã£o min-max dos dados\n",
    "  X_train_min = X_train.min(axis=0) # valor mÃ­nimo de cada atributo/coluna\n",
    "  X_train_max = X_train.max(axis=0) # valor mÃ¡ximo de cada atributo/coluna\n",
    "  X = (X - X_train_min) / (X_train_max - X_train_min) # normalizando os valores das variÃ¡veis x na mesma escala dos dados de treino\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_1co_direto(X, Y, W, M, f_ativ_oculta, f_ativ_saida, f_custo): # sentido direto da rede MLP com 1 camada oculta\n",
    "  U = X @ W\n",
    "  Zi = np.array(list(map(globals()[f_ativ_oculta], U))) # matriz de saÃ­da da camada oculta com a funÃ§Ã£o de ativaÃ§Ã£o\n",
    "  Z = np.c_[np.ones(Zi.shape[0]), Zi] # inserindo o termo de viÃ©s\n",
    "  R = Z @ M\n",
    "  Y_pred = np.array(list(map(globals()[f_ativ_saida], R))) # vetor de saÃ­da com a funÃ§Ã£o de ativaÃ§Ã£o\n",
    "  erro = Y - Y_pred\n",
    "  if f_custo == 'MSE':\n",
    "    custo = (1/(2*Y.shape[0])) * (erro**2).sum() # computando o erro quadrÃ¡tico mÃ©dio\n",
    "  if f_custo == 'entropia':\n",
    "    custo = (-1/Y.shape[0]) * (Y * np.log(Y_pred)).sum() # computando a entropia cruzada\n",
    "  return Z, Y_pred, erro, custo\n",
    "\n",
    "def MLP_train(X_train, Y_train, X_validacao, Y_validacao, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = True): # treinamento da rede MLP\n",
    "  # InicializaÃ§Ã£o dos parÃ¢metros\n",
    "  D = X_train.shape[1] # nÃºmero de dimensÃµes de entrada (atributos)\n",
    "  if f_ativ_oculta == 'relu':\n",
    "    W = np.sqrt(2/(D+1)) * np.random.normal(size = (D, n_neuronios)) # inicializaÃ§Ã£o da matriz de parÃ¢metros da camada de entrada => camada oculta\n",
    "    W = np.r_[0.01*np.ones((1, n_neuronios)), W] # inicializaÃ§Ã£o do viÃ©s de cada neurÃ´nio = 0.01\n",
    "  else:\n",
    "    W = np.sqrt(1/(D+1)) * np.random.normal(size = (D, n_neuronios)) # inicializaÃ§Ã£o da matriz de parÃ¢metros da camada de entrada => camada oculta\n",
    "    W = np.r_[np.zeros((1, n_neuronios)), W] # inicializaÃ§Ã£o do viÃ©s de cada neurÃ´nio = 0\n",
    "  W_ant = W # matriz W da iteraÃ§Ã£o anterior, para termo de momentum\n",
    "  \n",
    "  K = Y_train.shape[1] # nÃºmero de dimensÃµes de saÃ­da\n",
    "  if f_ativ_saida == 'relu':\n",
    "    M = np.sqrt(2/(n_neuronios + 1)) * np.random.normal(size = (n_neuronios, K)) # inicializaÃ§Ã£o da matriz de parÃ¢metros da camada oculta => camada de saÃ­da\n",
    "    M = np.r_[0.01*np.ones((1, K)), M] # inicializaÃ§Ã£o do viÃ©s de cada neurÃ´nio = 0.01\n",
    "  else:\n",
    "    M = np.sqrt(1/(n_neuronios + 1)) * np.random.normal(size = (n_neuronios, K)) # inicializaÃ§Ã£o da matriz de parÃ¢metros da camada oculta => camada de saÃ­da\n",
    "    M = np.r_[np.zeros((1, K)), M] # inicializaÃ§Ã£o do viÃ©s de cada neurÃ´nio = 0\n",
    "  M_ant = M # matriz M da iteraÃ§Ã£o anterior, para termo de momentum\n",
    "\n",
    "  # Etapa de treinamento e validaÃ§Ã£o\n",
    "  custo_train_it = [] # histÃ³rico dos valores da funÃ§Ã£o custo de treino em cada iteraÃ§Ã£o (mini-batch), geralmente utilizado com muitos dados devido ao custo de execuÃ§Ã£o do algoritmo\n",
    "  custo_validacao_ep = [] # histÃ³rico dos valores da funÃ§Ã£o custo de validaÃ§Ã£o em cada Ã©poca\n",
    "  custo_validacao_min = np.inf # inicializando o custo mÃ­nimo de validaÃ§Ã£o como infinito (para escolher melhor modelo durante o treinamento/validaÃ§Ã£o)\n",
    "  n_iteracoes = int(np.ceil(X_train.shape[0] / B)) # nÃºmero de iteraÃ§Ãµes (mini-batches) por Ã©poca\n",
    "  for epoca in range(n_epocas):\n",
    "    I_train = np.random.permutation(X_train.shape[0]) # permutaÃ§Ã£o dos Ã­ndices das observaÃ§Ãµes de treinamento\n",
    "    X_train_ep = X_train[I_train] # embaralhamento dos padrÃµes de treinamento\n",
    "    Y_train_ep = Y_train[I_train] # embaralhamento dos dados de saÃ­da de treinamento\n",
    "    alfa = alfa_0 / (1 + epoca) # decaimento exponencial da taxa de aprendizagem\n",
    "    \n",
    "    for t in range(n_iteracoes):\n",
    "      X_t = X_train_ep[(t*B):((t+1)*B),] # selecionando apenas os padrÃµes do mini-batch\n",
    "      X_t = np.c_[np.ones(X_t.shape[0]), X_t] # inserindo o termo de viÃ©s\n",
    "      Y_t = Y_train_ep[(t*B):((t+1)*B),] # selecionando apenas as saÃ­das dos padrÃµes do mini-batch\n",
    "      \n",
    "      MLP_dir_train = MLP_1co_direto(X_t, Y_t, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de treinamento da iteraÃ§Ã£o\n",
    "      erro = MLP_dir_train[2]\n",
    "      custo_train_it.append(MLP_dir_train[3]) # custo de treino da iteraÃ§Ã£o (mini-batch)\n",
    "\n",
    "      Z_t = MLP_dir_train[0]\n",
    "      R = Z_t @ M\n",
    "      dY = -erro # gradiente local da camada de saÃ­da (para os casos especÃ­ficos tratados aqui)\n",
    "      M_aux = M # matriz de parÃ¢metros auxiliar (para manter a matriz de parÃ¢metros da iteraÃ§Ã£o anterior)\n",
    "      M_reg = M # matriz dos parÃ¢metros a serem regularizados\n",
    "      M_reg[0,:] = np.zeros((1, K)) # removendo o termo de viÃ©s da regularizaÃ§Ã£o\n",
    "      M += -(alfa/B) * (Z_t.T @ dY + termo_reg * M_reg) + momentum * (M - M_ant) # atualizaÃ§Ã£o dos parÃ¢metros da camada oculta => camada de saÃ­da\n",
    "      M_ant = M_aux # atualizando a matriz de parÃ¢metros da iteraÃ§Ã£o anterior\n",
    "\n",
    "      U = X_t @ W\n",
    "      dU = np.array(list(map(globals()['deriv_' + f_ativ_oculta], U))) # derivada da funÃ§Ã£o de ativaÃ§Ã£o da camada oculta\n",
    "      dZ = dU * (dY @ M[1:,].T) # gradiente local da camada oculta\n",
    "      W_aux = W # matriz de parÃ¢metros auxiliar (para manter a matriz de parÃ¢metros da iteraÃ§Ã£o anterior)\n",
    "      W_reg = W # matriz dos parÃ¢metros a serem regularizados (nÃ£o se remove o termo de viÃ©s da camada oculta da regularizaÃ§Ã£o porque nÃ£o se tem uma saÃ­da desejada)\n",
    "      W += -(alfa/B) * (X_t.T @ dZ + termo_reg * W_reg) + momentum * (W - W_ant) # atualizaÃ§Ã£o dos parÃ¢metros da camada de entrada => camada oculta\n",
    "      W_ant = W_aux # atualizando a matriz de parÃ¢metros da iteraÃ§Ã£o anterior\n",
    "\n",
    "    if validacao == True:\n",
    "      MLP_validacao = MLP_1co_direto(X_validacao, Y_validacao, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validaÃ§Ã£o\n",
    "      custo_validacao = MLP_validacao[3] # custo mÃ©dio de validaÃ§Ã£o da Ã©poca\n",
    "      custo_validacao_ep.append(custo_validacao)\n",
    "\n",
    "      if custo_validacao < custo_validacao_min:\n",
    "        custo_validacao_min = custo_validacao\n",
    "        W_melhor = W # atualizando matriz de parÃ¢metros associados ao melhor modelo durante o treinamento/validaÃ§Ã£o\n",
    "        M_melhor = M # atualizando matriz de parÃ¢metros associados ao melhor modelo durante o treinamento/validaÃ§Ã£o\n",
    "    \n",
    "    else:\n",
    "      W_melhor = W\n",
    "      M_melhor = M\n",
    "  return W_melhor, M_melhor, custo_train_it, custo_validacao_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-7798599b2a64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[1;31m# Etapa de treinamento e validaÃ§Ã£o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m   \u001b[0mrede_MLP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_validacao\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_validacao\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_ativ_oculta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_ativ_saida\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_custo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malfa_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epocas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neuronios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtermo_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidacao\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m   \u001b[1;33m(\u001b[0m\u001b[0mW_hp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM_hp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrede_MLP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrede_MLP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-f00504fd53d0>\u001b[0m in \u001b[0;36mMLP_train\u001b[1;34m(X_train, Y_train, X_validacao, Y_validacao, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao)\u001b[0m\n\u001b[0;32m     48\u001b[0m       \u001b[0mY_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train_ep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# selecionando apenas as saÃ­das dos padrÃµes do mini-batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m       \u001b[0mMLP_dir_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_1co_direto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_ativ_oculta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_ativ_saida\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_custo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sentido direto da rede MLP aplicado aos dados de treinamento da iteraÃ§Ã£o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m       \u001b[0merro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_dir_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m       \u001b[0mcusto_train_it\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLP_dir_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# custo de treino da iteraÃ§Ã£o (mini-batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-f00504fd53d0>\u001b[0m in \u001b[0;36mMLP_1co_direto\u001b[1;34m(X, Y, W, M, f_ativ_oculta, f_ativ_saida, f_custo)\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# inserindo o termo de viÃ©s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf_ativ_saida\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# vetor de saÃ­da com a funÃ§Ã£o de ativaÃ§Ã£o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[0merro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mf_custo\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MSE'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-938ca5820e37>\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msoftmax_dif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# DivisÃ£o das amostras e normalizaÃ§Ã£o dos dados\n",
    "I = np.random.permutation(n) # permutaÃ§Ã£o dos Ã­ndices das observaÃ§Ãµes\n",
    "(X_train, X_validacao, X_teste) = (X[I][:n_train,], X[I][n_train:(n_train + n_validacao),], X[I][(n - n_teste):,])\n",
    "(Y_train, Y_validacao, Y_teste) = (Y[I][:n_train,], Y[I][n_train:(n_train + n_validacao),], Y[I][(n - n_teste):,])\n",
    "\n",
    "X_train = norm_min_max(X_train, X_train)\n",
    "X_validacao = norm_min_max(X_validacao, X_train)\n",
    "X_teste = norm_min_max(X_teste, X_train)\n",
    "\n",
    "X_validacao = np.c_[np.ones(n_validacao), X_validacao] # inserindo o termo de viÃ©s\n",
    "X_teste = np.c_[np.ones(n_teste), X_teste] # inserindo o termo de viÃ©s\n",
    "\n",
    "# Busca pelos hiperparÃ¢metros Ã³timos\n",
    "n_iteracoes_hp = 1000 # nÃºmero de iteraÃ§Ãµes na busca pelos hiperparÃ¢metros Ã³timos\n",
    "f_ativ_oculta = 'relu'\n",
    "f_ativ_saida = 'softmax'\n",
    "f_custo = 'entropia'\n",
    "\n",
    "custo_hp_min = np.inf # inicializando o custo mÃ­nimo de validaÃ§Ã£o como infinito (para escolher melhor combinaÃ§Ã£o de hiperparÃ¢metros)\n",
    "for i in range(n_iteracoes_hp):\n",
    "  # HiperparÃ¢metros\n",
    "  alfa_0 = 10**np.random.uniform(-5, -1) # taxa de aprendizagem inicial\n",
    "  n_epocas = np.random.randint(200, 500) # nÃºmero de Ã©pocas\n",
    "  momentum = np.random.uniform(0.5, 1) # termo de momentum\n",
    "  n_neuronios = np.random.randint(11, 200) # nÃºmero de neurÃ´nios\n",
    "  B = np.random.randint(10, 100) # quantidade de padrÃµes utilizados por mini-batch durante o treinamento\n",
    "  termo_reg = np.random.uniform(0.01, 0.1) # termo de regularizaÃ§Ã£o\n",
    "\n",
    "  # Etapa de treinamento e validaÃ§Ã£o\n",
    "  rede_MLP = MLP_train(X_train, Y_train, X_validacao, Y_validacao, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = True)\n",
    "  (W_hp, M_hp) = (rede_MLP[0], rede_MLP[1]) \n",
    "\n",
    "  MLP_validacao = MLP_1co_direto(X_validacao, Y_validacao, W_hp, M_hp, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validaÃ§Ã£o\n",
    "  custo_validacao = MLP_validacao[3] # custo de validaÃ§Ã£o do melhor modelo\n",
    "\n",
    "  if custo_validacao < custo_hp_min:\n",
    "    custo_hp_min = custo_validacao\n",
    "    (W_melhor, M_melhor) = (W_hp, M_hp) # atualizando matrizes de parÃ¢metros associados ao melhor modelo durante o treinamento/validaÃ§Ã£o\n",
    "    (alfa_0_melhor, n_epocas_melhor, momentum_melhor, n_neuronios_melhor, B_melhor, termo_reg_melhor) = (alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg) # atualizando melhor combinaÃ§Ã£o de hiperparÃ¢metros\n",
    "    (custo_train_it_melhor, custo_validacao_ep_melhor) = (rede_MLP[2], rede_MLP[3])\n",
    "\n",
    "plt.plot(custo_train_it_melhor) # curva de aprendizagem de train para a melhor combinaÃ§Ã£o de hiperparÃ¢metros\n",
    "plt.xlabel(\"IteraÃ§Ã£o\")\n",
    "plt.ylabel(\"Entropia cruzada\")\n",
    "plt.title(\"Treinamento via SGD com momentum\");\n",
    "\n",
    "print(\"HiperparÃ¢metros do melhor modelo:\")\n",
    "print(\"taxa de aprendizagem inicial: %.3f, nÃºmero de Ã©pocas: %d, termo de momentum: %.2f, nÃºmero de neurÃ´nios: %d, tamanho do mini-batch: %d e termo de regularizaÃ§Ã£o: %.2f\" % \n",
    "      (alfa_0_melhor, n_epocas_melhor, momentum_melhor, n_neuronios_melhor, B_melhor, termo_reg_melhor), end = '\\n\\n')\n",
    "\n",
    "# Etapa de teste (GeneralizaÃ§Ã£o)\n",
    "MLP_teste = MLP_1co_direto(X_teste, Y_teste, W_melhor, M_melhor, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "custo_teste = MLP_teste[3] # entropia cruzada de teste\n",
    "print(\"Entropia cruzada de teste: %.4f\" % custo_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custo_validacao_ep_melhor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9427d54735d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcusto_validacao_ep_melhor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# curva de aprendizagem de validaÃ§Ã£o para a melhor combinaÃ§Ã£o de hiperparÃ¢metros\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ãpoca\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Entropia cruzada\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ValidaÃ§Ã£o\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'custo_validacao_ep_melhor' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(custo_validacao_ep_melhor) # curva de aprendizagem de validaÃ§Ã£o para a melhor combinaÃ§Ã£o de hiperparÃ¢metros\n",
    "plt.xlabel(\"Ãpoca\")\n",
    "plt.ylabel(\"Entropia cruzada\")\n",
    "plt.title(\"ValidaÃ§Ã£o\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alfa_0_melhor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-01b61e68fd42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf_ativ_saida\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'softmax'\u001b[0m \u001b[1;31m# jÃ¡ que se trata de um problema multiclasse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf_custo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'entropia'\u001b[0m \u001b[1;31m# jÃ¡ que se trata de um problema de classificaÃ§Ã£o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0malfa_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malfa_0_melhor\u001b[0m \u001b[1;31m# taxa de aprendizagem inicial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mn_epocas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epocas_melhor\u001b[0m \u001b[1;31m# nÃºmero de Ã©pocas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmomentum_melhor\u001b[0m \u001b[1;31m# termo de momentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alfa_0_melhor' is not defined"
     ]
    }
   ],
   "source": [
    "# HiperparÃ¢metros\n",
    "f_ativ_oculta = 'relu' # jÃ¡ que se trata de um problema de classificaÃ§Ã£o\n",
    "f_ativ_saida = 'softmax' # jÃ¡ que se trata de um problema multiclasse\n",
    "f_custo = 'entropia' # jÃ¡ que se trata de um problema de classificaÃ§Ã£o\n",
    "alfa_0 = alfa_0_melhor # taxa de aprendizagem inicial\n",
    "n_epocas = n_epocas_melhor # nÃºmero de Ã©pocas\n",
    "momentum = momentum_melhor # termo de momentum\n",
    "n_neuronios = n_neuronios_melhor # nÃºmero de neurÃ´nios\n",
    "B = B_melhor # quantidade de padrÃµes utilizados por mini-batch durante o treinamento\n",
    "termo_reg = termo_reg_melhor # termo de regularizaÃ§Ã£o\n",
    "\n",
    "# Etapa de treinamento\n",
    "X_retrain = np.r_[X_train, X_validacao[:, 1:]] # juntando dados de treino e validaÃ§Ã£o\n",
    "Y_retrain = np.r_[Y_train, Y_validacao] # juntando dados de treino e validaÃ§Ã£o\n",
    "\n",
    "rede_MLP = MLP_train(X_retrain, Y_retrain, None, None, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = False)\n",
    "(W, M) = (rede_MLP[0], rede_MLP[1]) # matrizes de parÃ¢metros da rede MLP retreinada\n",
    "\n",
    "plt.plot(rede_MLP[2]) # curva de aprendizagem de treino\n",
    "plt.xlabel(\"IteraÃ§Ã£o\")\n",
    "plt.ylabel(\"Entropia cruzada\")\n",
    "plt.title(\"Treinamento via SGD com momentum\");\n",
    "\n",
    "# Etapa de teste (GeneralizaÃ§Ã£o)\n",
    "MLP_teste = MLP_1co_direto(X_teste, Y_teste, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "custo_teste = MLP_teste[3] # custo de teste\n",
    "print(\"Entropia cruzada de teste (normalizado): %.4f\" % custo_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acertos(Y, Y_pred): # retorna o nÃºmero e a taxa de acertos (acurÃ¡cia) gerais de classificaÃ§Ã£o\n",
    "  n = Y.shape[0] # quantidade de padrÃµes\n",
    "  n_acertos = 0\n",
    "  for i in range(n):\n",
    "    classe_pred = np.argmax(Y_pred[i,:])\n",
    "    if Y[i, classe_pred] == 1:\n",
    "      n_acertos += 1\n",
    "  p_acertos = n_acertos/n\n",
    "  return n_acertos, p_acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e9ae00e7ba6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# inserindo o termo de viÃ©s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdireto_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_1co_direto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_ativ_oculta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_ativ_saida\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_custo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sentido direto da rede MLP aplicado aos dados de treino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mY_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdireto_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# valores preditos de treino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macertos_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macertos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# acertos de treino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0macertos_classe_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macertos_classe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# acertos de treino por classe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_2 = np.c_[np.ones(n_train), X_train] # inserindo o termo de viÃ©s\n",
    "direto_train = MLP_1co_direto(X_train_2, Y_train, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de treino\n",
    "Y_pred_train = direto_train[1] # valores preditos de treino\n",
    "acertos_train = acertos(Y_train, Y_pred_train) # acertos de treino\n",
    "acertos_classe_train = acertos_classe(Y_train, Y_pred_train) # acertos de treino por classe\n",
    "\n",
    "direto_validacao = MLP_1co_direto(X_validacao, Y_validacao, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validaÃ§Ã£o\n",
    "Y_pred_validacao = direto_validacao[1] # valores preditos de validaÃ§Ã£o\n",
    "acertos_validacao = acertos(Y_validacao, Y_pred_validacao) # acertos de validaÃ§Ã£o\n",
    "acertos_classe_validacao = acertos_classe(Y_validacao, Y_pred_validacao) # acertos de validaÃ§Ã£o por classe\n",
    "\n",
    "direto_teste = MLP_1co_direto(X_teste, Y_teste, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "Y_pred_teste = direto_teste[1] # valores preditos de teste\n",
    "acertos_teste = acertos(Y_teste, Y_pred_teste) # acertos de teste\n",
    "acertos_classe_teste = acertos_classe(Y_teste, Y_pred_teste) # acertos de teste por classe\n",
    "\n",
    "print(\"AcurÃ¡cia de treino, validaÃ§Ã£o e teste: %.2f%%, %.2f%% e %.2f%%\" % (100*acertos_treino[1], 100*acertos_validacao[1], 100*acertos_teste[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
