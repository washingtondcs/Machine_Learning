{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEKLajefi9HH"
   },
   "source": [
    "Universidade Federal do Ceará\n",
    "\n",
    "Disciplina: Aprendizagem de Máquina\n",
    "\n",
    "Programa de Pós-Graduação em Ciências da Computação\n",
    "\n",
    "Aluno: Alessandro Macêdo de Araújo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maS-OtphjA5U"
   },
   "source": [
    "# Questão 1\n",
    "Considere o conjunto de dados disponível em **concrete.csv**, organizado em 9 colunas, sendo as 8 primeiras colunas os atributos e a última coluna a saída. Os 8 atributos referem-se à caracterização de diferentes tipos de concreto para construção civil. A saída é a resistência à compressão do concreto (em megapascals, MPa). Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/d/4353."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zSNNE1pei6ZA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pk8OcO2kT9j"
   },
   "source": [
    "Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VU-4EKtSkVbK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[540.  ,   0.  ,   0.  , ..., 676.  ,  28.  ,  79.99],\n",
       "       [540.  ,   0.  ,   0.  , ..., 676.  ,  28.  ,  61.89],\n",
       "       [332.5 , 142.5 ,   0.  , ..., 594.  , 270.  ,  40.27],\n",
       "       ...,\n",
       "       [148.5 , 139.4 , 108.6 , ..., 780.  ,  28.  ,  23.7 ],\n",
       "       [159.1 , 186.7 ,   0.  , ..., 788.9 ,  28.  ,  32.77],\n",
       "       [260.9 , 100.5 ,  78.3 , ..., 761.5 ,  28.  ,  32.4 ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_concrete = np.genfromtxt('./Dados/concrete.csv', delimiter = ',', skip_header = 0)\n",
    "dados_concrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3nCtOvIglFCZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de variáveis x:\n",
      "[[ 540.     0.     0.  ... 1040.   676.    28. ]\n",
      " [ 540.     0.     0.  ... 1055.   676.    28. ]\n",
      " [ 332.5  142.5    0.  ...  932.   594.   270. ]\n",
      " ...\n",
      " [ 148.5  139.4  108.6 ...  892.4  780.    28. ]\n",
      " [ 159.1  186.7    0.  ...  989.6  788.9   28. ]\n",
      " [ 260.9  100.5   78.3 ...  864.5  761.5   28. ]]\n",
      "\n",
      "Vetor da variável y:\n",
      "[[79.99]\n",
      " [61.89]\n",
      " [40.27]\n",
      " ...\n",
      " [23.7 ]\n",
      " [32.77]\n",
      " [32.4 ]]\n"
     ]
    }
   ],
   "source": [
    "X = dados_concrete[:, 0:-1]\n",
    "y = dados_concrete[:, [-1]]\n",
    "print(\"Matriz de variáveis x:\")\n",
    "print(X, end = '\\n\\n')\n",
    "print(\"Vetor da variável y:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlIFIlOGpBKJ"
   },
   "source": [
    "## a)\n",
    "Considere um modelo de regressão não linear baseado em redes neurais artificiais. Separe os dados aleatoriamente em treino, validação e teste (por exemplo, 60%, 20% e 20%). Nesse cenário, treine e avalie o modelo abaixo:\n",
    "- **MLP (multilayer perceptron)**: 1 camada oculta e treinamento em minibatch via gradiente descendente estocástico com termo de momentum. Utilize o conjunto de validação para ajustar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAw_XmLdozCx"
   },
   "source": [
    "Informações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hYDfMwELo8P7"
   },
   "outputs": [],
   "source": [
    "n = X.shape[0] # tamanho da amostra original\n",
    "D = X.shape[1] # número de dimensões de entrada\n",
    "K = y.shape[1] # número de dimensões de saída\n",
    "n_treino = round(0.6*n) # tamanho da amostra de treino\n",
    "n_validacao = round(0.2*n) # tamanho da amostra de validação\n",
    "n_teste = n - n_treino - n_validacao # tamanho da amostra de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw96KsNKqULJ"
   },
   "source": [
    "Funções básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f_TTY14WqVRX"
   },
   "outputs": [],
   "source": [
    "def norm_min_max(X, X_treino): # normalização min-max dos dados\n",
    "  X_treino_min = X_treino.min(axis=0) # valor mínimo de cada atributo/coluna\n",
    "  X_treino_max = X_treino.max(axis=0) # valor máximo de cada atributo/coluna\n",
    "  X = (X - X_treino_min) / (X_treino_max - X_treino_min) # normalizando os valores das variáveis x na mesma escala dos dados de treino\n",
    "  return X\n",
    "\n",
    "def desnorm_min_max(Y_treino_original, Y_pred_norm): # desnormalização min-max dos dados\n",
    "  Y_treino_min = Y_treino_original.min(axis=0) # valor mínimo de treino das variáveis y\n",
    "  Y_treino_max = Y_treino_original.max(axis=0) # valor máximo de treino das variáveis y\n",
    "  Y_pred = Y_pred_norm * (Y_treino_max - Y_treino_min) + Y_treino_min # desnormalizando os valores das variáveis y para a escala original\n",
    "  return Y_pred\n",
    "\n",
    "def norm_escore_z(X, X_treino): # normalização escore-z dos dados\n",
    "  X_treino_med = X_treino.mean(axis=0) # valor médio de cada atributo/coluna\n",
    "  X_treino_dp = X_treino.std(axis=0) # desvio padrão de cada atributo/coluna\n",
    "  X = (X - X_treino_med) / X_treino_dp # normalizando os valores das variáveis x na mesma escala dos dados de treino\n",
    "  return X\n",
    "\n",
    "def desnorm_escore_z(Y_treino_original, Y_pred_norm): # desnormalização escore-z dos dados\n",
    "  Y_treino_med = Y_treino_original.mean(axis=0) # valor médio de treino das variáveis y\n",
    "  Y_treino_dp = Y_treino_original.std(axis=0) # desvio padrão de treino das variáveis y\n",
    "  Y_pred = Y_pred_norm * Y_treino_dp + Y_treino_med # desnormalizando os valores das variáveis y para a escala original\n",
    "  return Y_pred\n",
    "\n",
    "def identidade(z): # função identidade\n",
    "  return z\n",
    "\n",
    "def deriv_identidade(z): # derivada da função identidade\n",
    "  derivada = np.ones(z.shape[0])\n",
    "  return derivada\n",
    "\n",
    "def sigmoide(z): # função sigmóide\n",
    "  result = 1/(1 + np.exp(-(z)))\n",
    "  return result\n",
    "\n",
    "def deriv_sigmoide(z): # derivada da função sigmóide\n",
    "  s = sigmoide(z)\n",
    "  derivada = s*(1-s)\n",
    "  return derivada\n",
    "\n",
    "tanh = np.tanh\n",
    "\n",
    "def deriv_tanh(z): # derivada da função tangente hiperbólica\n",
    "  derivada = 1 - np.tanh(z)**2\n",
    "  return derivada\n",
    "\n",
    "def ReLU(z): # função Rectified Linear Unit (ReLU)\n",
    "  result = np.maximum(0, z)\n",
    "  return result \n",
    "\n",
    "def deriv_ReLU(z): # derivada da função Rectified Linear Unit (ReLU)\n",
    "  return 1 * (z > 0) # transforma False ou True em 0 ou 1\n",
    "\n",
    "def softmax(z): # função softmax (eixo da soma modificado para ser utilizada em conjunto com a função map() e retornar mesmo resultado)\n",
    "  exps = np.exp(z - np.max(z)) # subtrair do valor máximo não altera o valor da função e ajuda a evitar overflow\n",
    "  result = exps/(np.sum(exps, axis=0))\n",
    "  return result\n",
    "\n",
    "def softmax_2(z): # função softmax (ATENÇÃO: a quantidade de classes deve ser a quantidade de colunas de \"z\", caso contrário o somatório deve ser no outro eixo)\n",
    "  exps = np.exp(z - np.max(z)) # subtrair do valor máximo não altera o valor da função e ajuda a evitar overflow\n",
    "  result = exps/(np.sum(exps, axis=1)).reshape(exps.shape[0], 1)\n",
    "  return result\n",
    "\n",
    "def deriv_softmax(z): # derivada da função softmax\n",
    "  s = softmax(z)\n",
    "  derivada = s*(1-s)\n",
    "  return derivada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaA1OGT3r3nM"
   },
   "source": [
    "Rede MLP (multilayer perceptron) com 1 camada oculta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGMaSUe41WqY"
   },
   "source": [
    "Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E41Ps8joLXUi"
   },
   "outputs": [],
   "source": [
    "def MLP_1co_direto(X, Y, W, M, f_ativ_oculta, f_ativ_saida, f_custo): # sentido direto da rede MLP com 1 camada oculta\n",
    "  U = X @ W\n",
    "  Zi = np.array(list(map(globals()[f_ativ_oculta], U))) # matriz de saída da camada oculta com a função de ativação\n",
    "  Z = np.c_[np.ones(Zi.shape[0]), Zi] # inserindo o termo de viés\n",
    "  R = Z @ M\n",
    "  Y_pred = np.array(list(map(globals()[f_ativ_saida], R))) # vetor de saída com a função de ativação\n",
    "  erro = Y - Y_pred\n",
    "  if f_custo == 'MSE':\n",
    "    custo = (1/(2*Y.shape[0])) * (erro**2).sum() # computando o erro quadrático médio\n",
    "  if f_custo == 'entropia':\n",
    "    custo = (-1/Y.shape[0]) * (Y * np.log(Y_pred)).sum() # computando a entropia cruzada\n",
    "  return Z, Y_pred, erro, custo\n",
    "\n",
    "def MLP_treino(X_treino, Y_treino, X_validacao, Y_validacao, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = True): # treinamento da rede MLP\n",
    "  # Inicialização dos parâmetros\n",
    "  D = X_treino.shape[1] # número de dimensões de entrada (atributos)\n",
    "  if f_ativ_oculta == 'ReLU':\n",
    "    W = np.sqrt(2/(D+1)) * np.random.normal(size = (D, n_neuronios)) # inicialização da matriz de parâmetros da camada de entrada => camada oculta\n",
    "    W = np.r_[0.01*np.ones((1, n_neuronios)), W] # inicialização do viés de cada neurônio = 0.01\n",
    "  else:\n",
    "    W = np.sqrt(1/(D+1)) * np.random.normal(size = (D, n_neuronios)) # inicialização da matriz de parâmetros da camada de entrada => camada oculta\n",
    "    W = np.r_[np.zeros((1, n_neuronios)), W] # inicialização do viés de cada neurônio = 0\n",
    "  W_ant = W # matriz W da iteração anterior, para termo de momentum\n",
    "  \n",
    "  K = Y_treino.shape[1] # número de dimensões de saída\n",
    "  if f_ativ_saida == 'ReLU':\n",
    "    M = np.sqrt(2/(n_neuronios + 1)) * np.random.normal(size = (n_neuronios, K)) # inicialização da matriz de parâmetros da camada oculta => camada de saída\n",
    "    M = np.r_[0.01*np.ones((1, K)), M] # inicialização do viés de cada neurônio = 0.01\n",
    "  else:\n",
    "    M = np.sqrt(1/(n_neuronios + 1)) * np.random.normal(size = (n_neuronios, K)) # inicialização da matriz de parâmetros da camada oculta => camada de saída\n",
    "    M = np.r_[np.zeros((1, K)), M] # inicialização do viés de cada neurônio = 0\n",
    "  M_ant = M # matriz M da iteração anterior, para termo de momentum\n",
    "\n",
    "  # Etapa de treinamento e validação\n",
    "  custo_treino_it = [] # histórico dos valores da função custo de treino em cada iteração (mini-batch), geralmente utilizado com muitos dados devido ao custo de execução do algoritmo\n",
    "  custo_validacao_ep = [] # histórico dos valores da função custo de validação em cada época\n",
    "  custo_validacao_min = np.inf # inicializando o custo mínimo de validação como infinito (para escolher melhor modelo durante o treinamento/validação)\n",
    "  n_iteracoes = int(np.ceil(X_treino.shape[0] / B)) # número de iterações (mini-batches) por época\n",
    "  for epoca in range(n_epocas):\n",
    "    I_treino = np.random.permutation(X_treino.shape[0]) # permutação dos índices das observações de treinamento\n",
    "    X_treino_ep = X_treino[I_treino] # embaralhamento dos padrões de treinamento\n",
    "    Y_treino_ep = Y_treino[I_treino] # embaralhamento dos dados de saída de treinamento\n",
    "    alfa = alfa_0 / (1 + epoca) # decaimento exponencial da taxa de aprendizagem\n",
    "    \n",
    "    for t in range(n_iteracoes):\n",
    "      X_t = X_treino_ep[(t*B):((t+1)*B),] # selecionando apenas os padrões do mini-batch\n",
    "      X_t = np.c_[np.ones(X_t.shape[0]), X_t] # inserindo o termo de viés\n",
    "      Y_t = Y_treino_ep[(t*B):((t+1)*B),] # selecionando apenas as saídas dos padrões do mini-batch\n",
    "      \n",
    "      MLP_dir_treino = MLP_1co_direto(X_t, Y_t, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de treinamento da iteração\n",
    "      erro = MLP_dir_treino[2]\n",
    "      custo_treino_it.append(MLP_dir_treino[3]) # custo de treino da iteração (mini-batch)\n",
    "\n",
    "      Z_t = MLP_dir_treino[0]\n",
    "      R = Z_t @ M\n",
    "      dY = -erro # gradiente local da camada de saída (para os casos específicos tratados aqui)\n",
    "      M_aux = M # matriz de parâmetros auxiliar (para manter a matriz de parâmetros da iteração anterior)\n",
    "      M_reg = M # matriz dos parâmetros a serem regularizados\n",
    "      M_reg[0,:] = np.zeros((1, K)) # removendo o termo de viés da regularização\n",
    "      M += -(alfa/B) * (Z_t.T @ dY + termo_reg * M_reg) + momentum * (M - M_ant) # atualização dos parâmetros da camada oculta => camada de saída\n",
    "      M_ant = M_aux # atualizando a matriz de parâmetros da iteração anterior\n",
    "\n",
    "      U = X_t @ W\n",
    "      dU = np.array(list(map(globals()['deriv_' + f_ativ_oculta], U))) # derivada da função de ativação da camada oculta\n",
    "      dZ = dU * (dY @ M[1:,].T) # gradiente local da camada oculta\n",
    "      W_aux = W # matriz de parâmetros auxiliar (para manter a matriz de parâmetros da iteração anterior)\n",
    "      W_reg = W # matriz dos parâmetros a serem regularizados (não se remove o termo de viés da camada oculta da regularização porque não se tem uma saída desejada)\n",
    "      W += -(alfa/B) * (X_t.T @ dZ + termo_reg * W_reg) + momentum * (W - W_ant) # atualização dos parâmetros da camada de entrada => camada oculta\n",
    "      W_ant = W_aux # atualizando a matriz de parâmetros da iteração anterior\n",
    "\n",
    "    if validacao == True:\n",
    "      MLP_validacao = MLP_1co_direto(X_validacao, Y_validacao, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validação\n",
    "      custo_validacao = MLP_validacao[3] # custo médio de validação da época\n",
    "      custo_validacao_ep.append(custo_validacao)\n",
    "\n",
    "      if custo_validacao < custo_validacao_min:\n",
    "        custo_validacao_min = custo_validacao\n",
    "        W_melhor = W # atualizando matriz de parâmetros associados ao melhor modelo durante o treinamento/validação\n",
    "        M_melhor = M # atualizando matriz de parâmetros associados ao melhor modelo durante o treinamento/validação\n",
    "    \n",
    "    else:\n",
    "      W_melhor = W\n",
    "      M_melhor = M\n",
    "  return W_melhor, M_melhor, custo_treino_it, custo_validacao_ep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaTcQXqY1IGZ"
   },
   "source": [
    "Busca pelos hiperparâmetros ótimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHUC4a-sr2z8"
   },
   "outputs": [],
   "source": [
    "# Divisão das amostras e normalização dos dados\n",
    "I = np.random.permutation(n) # permutação dos índices das observações\n",
    "(X_treino, X_validacao, X_teste) = (X[I][:n_treino,], X[I][n_treino:(n_treino + n_validacao),], X[I][(n - n_teste):,])\n",
    "(y_treino_original, y_validacao_original, y_teste_original) = (y[I][:n_treino,], y[I][n_treino:(n_treino + n_validacao),], y[I][(n - n_teste):,])\n",
    "\n",
    "(X_treino, y_treino) = (norm_min_max(X_treino, X_treino), norm_min_max(y_treino_original, y_treino_original))\n",
    "(X_validacao, y_validacao) = (norm_min_max(X_validacao, X_treino), norm_min_max(y_validacao_original, y_treino_original))\n",
    "(X_teste, y_teste) = (norm_min_max(X_teste, X_treino), norm_min_max(y_teste_original, y_treino_original))\n",
    "\n",
    "X_validacao = np.c_[np.ones(n_validacao), X_validacao] # inserindo o termo de viés\n",
    "X_teste = np.c_[np.ones(n_teste), X_teste] # inserindo o termo de viés\n",
    "\n",
    "# Busca pelos hiperparâmetros ótimos\n",
    "n_iteracoes_hp = 1000 # número de iterações na busca pelos hiperparâmetros ótimos\n",
    "f_ativ_oculta = 'tanh'\n",
    "f_ativ_saida = 'identidade'\n",
    "f_custo = 'MSE'\n",
    "\n",
    "custo_hp_min = np.inf # inicializando o custo mínimo de validação como infinito (para escolher melhor combinação de hiperparâmetros)\n",
    "for i in range(n_iteracoes_hp):\n",
    "  # Hiperparâmetros\n",
    "  alfa_0 = 10**np.random.uniform(-5, -1) # taxa de aprendizagem inicial\n",
    "  n_epocas = np.random.randint(50, 200) # número de épocas\n",
    "  momentum = np.random.uniform(0.5, 1) # termo de momentum\n",
    "  n_neuronios = np.random.randint(5, 100) # número de neurônios\n",
    "  B = np.random.randint(10, 100) # quantidade de padrões utilizados por mini-batch durante o treinamento\n",
    "  termo_reg = np.random.uniform(0.01, 0.1) # termo de regularização\n",
    "\n",
    "  # Etapa de treinamento e validação\n",
    "  rede_MLP = MLP_treino(X_treino, y_treino, X_validacao, y_validacao, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = True)\n",
    "  (W_hp, M_hp) = (rede_MLP[0], rede_MLP[1]) # matrizes de parâmetros associados ao melhor modelo para a combinação de hiperparâmetros da iteração atual\n",
    "\n",
    "  MLP_validacao = MLP_1co_direto(X_validacao, y_validacao, W_hp, M_hp, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validação\n",
    "  custo_validacao = MLP_validacao[3] # custo de validação do melhor modelo (normalizado)\n",
    "\n",
    "  if custo_validacao < custo_hp_min:\n",
    "    custo_hp_min = custo_validacao\n",
    "    (W_melhor, M_melhor) = (W_hp, M_hp) # atualizando matrizes de parâmetros associados ao melhor modelo durante o treinamento/validação\n",
    "    (alfa_0_melhor, n_epocas_melhor, momentum_melhor, n_neuronios_melhor, B_melhor, termo_reg_melhor) = (alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg) # atualizando melhor combinação de hiperparâmetros\n",
    "    (custo_treino_it_melhor, custo_validacao_ep_melhor) = (rede_MLP[2], rede_MLP[3])\n",
    "\n",
    "plt.plot(custo_treino_it_melhor) # curva de aprendizagem de treino para a melhor combinação de hiperparâmetros (normalizado)\n",
    "plt.xlabel(\"Iteração\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Treinamento via SGD com momentum\");\n",
    "\n",
    "print(\"Hiperparâmetros do melhor modelo:\")\n",
    "print(\"taxa de aprendizagem inicial: %.3f, número de épocas: %d, termo de momentum: %.2f, número de neurônios: %d, tamanho do mini-batch: %d e termo de regularização: %.2f\" % \n",
    "      (alfa_0_melhor, n_epocas_melhor, momentum_melhor, n_neuronios_melhor, B_melhor, termo_reg_melhor), end = '\\n\\n')\n",
    "\n",
    "# Etapa de teste (Generalização)\n",
    "MLP_teste = MLP_1co_direto(X_teste, y_teste, W_melhor, M_melhor, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "custo_teste = MLP_teste[3] # custo de teste (normalizado)\n",
    "print(\"MSE de teste (normalizado): %.4f\" % custo_teste, end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz9mykxvzlsd"
   },
   "source": [
    "Plotando a curva de aprendizagem de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IP5MZTtzs9k"
   },
   "outputs": [],
   "source": [
    "plt.plot(custo_validacao_ep_melhor) # curva de aprendizagem de validação para a melhor combinação de hiperparâmetros (normalizado)\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Validação\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTgCdw0j0xe0"
   },
   "source": [
    "Retreinamento com os dados de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gnd8a_Ik4236"
   },
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "f_ativ_oculta = 'tanh' # já que será utilizada uma rede MLP com apenas 1 camada oculta\n",
    "f_ativ_saida = 'identidade' # já que se trata de um problema de regressão\n",
    "f_custo = 'MSE' # já que se trata de um problema de regressão\n",
    "alfa_0 = alfa_0_melhor # taxa de aprendizagem inicial\n",
    "n_epocas = n_epocas_melhor # número de épocas\n",
    "momentum = momentum_melhor # termo de momentum\n",
    "n_neuronios = n_neuronios_melhor # número de neurônios\n",
    "B = B_melhor # quantidade de padrões utilizados por mini-batch durante o treinamento\n",
    "termo_reg = termo_reg_melhor # termo de regularização\n",
    "\n",
    "# Etapa de treinamento\n",
    "X_retreino = np.r_[X_treino, X_validacao[:, 1:]] # juntando dados de treino e validação\n",
    "y_retreino = np.r_[y_treino, y_validacao] # juntando dados de treino e validação\n",
    "\n",
    "rede_MLP = MLP_treino(X_retreino, y_retreino, None, None, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = False)\n",
    "(W, M) = (rede_MLP[0], rede_MLP[1]) # matrizes de parâmetros da rede MLP retreinada\n",
    "\n",
    "plt.plot(rede_MLP[2]) # curva de aprendizagem de treino (normalizado)\n",
    "plt.xlabel(\"Iteração\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Treinamento via SGD com momentum\");\n",
    "\n",
    "# Etapa de teste (Generalização)\n",
    "MLP_teste = MLP_1co_direto(X_teste, y_teste, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "custo_teste = MLP_teste[3] # custo de teste (normalizado)\n",
    "print(\"MSE de teste (normalizado): %.4f\" % custo_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd3dYL6xjksV"
   },
   "source": [
    "## b)\n",
    "Apresente as curvas da função custo nos conjuntos de treinamento e validação ao longo das épocas. Reporte também para os conjuntos de treino, validação e teste as métricas abaixo:\n",
    "- **RMSE (root mean squared error)**\n",
    "- **MAE (mean absolute error)**\n",
    "- **MRE (mean relative error)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEb4P2O1T2sf"
   },
   "source": [
    "Curvas da função custo apresentadas no item a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1zEekENAtEh"
   },
   "outputs": [],
   "source": [
    "def metricas_desnorm(y_original, y_pred_norm): # cálculo das métricas com base nos valores de y desnormalizados\n",
    "  y_pred = desnorm_min_max(y_treino_original, y_pred_norm)\n",
    "  erro = y_original - y_pred\n",
    "  RMSE = np.sqrt(np.mean(erro**2)) # computando a raiz do erro quadrático médio\n",
    "  MAE = np.mean(np.abs(erro)) # computando o erro absoluto médio\n",
    "  MRE = np.mean(np.abs(erro/y_original)) # computando o erro relativo médio\n",
    "  return y_pred, erro, RMSE, MAE, MRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3j4885obcllI"
   },
   "outputs": [],
   "source": [
    "X_treino_2 = np.c_[np.ones(n_treino), X_treino] # inserindo o termo de viés\n",
    "direto_treino = MLP_1co_direto(X_treino_2, y_treino, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de treino\n",
    "y_pred_treino = direto_treino[1] # valores preditos de treino\n",
    "metricas_treino = metricas_desnorm(y_treino_original, y_pred_treino) # métricas de treino\n",
    "\n",
    "direto_validacao = MLP_1co_direto(X_validacao, y_validacao, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validação\n",
    "y_pred_validacao = direto_validacao[1] # valores preditos de validação\n",
    "metricas_validacao = metricas_desnorm(y_validacao_original, y_pred_validacao) # métricas de validação\n",
    "\n",
    "direto_teste = MLP_1co_direto(X_teste, y_teste, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "y_pred_teste = direto_teste[1] # valores preditos de teste\n",
    "metricas_teste = metricas_desnorm(y_teste_original, y_pred_teste) # métricas de teste\n",
    "\n",
    "print(\"RMSE de treino, validação e teste: %.4f, %.4f e %.4f\" % (metricas_treino[2], metricas_validacao[2], metricas_teste[2]))\n",
    "print(\"MAE de treino, validação e teste: %.4f, %.4f e %.4f\" % (metricas_treino[3], metricas_validacao[3], metricas_teste[3]))\n",
    "print(\"MRE de treino, validação e teste: %.2f%%, %.2f%% e %.2f%%\" % (100*metricas_treino[4], 100*metricas_validacao[4], 100*metricas_teste[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWIfV8dnICXK"
   },
   "source": [
    "# Questão 2\n",
    "Considere o conjunto de dados disponível em **vowel.csv**, organizado em 11 colunas, sendo as 10 primeiras colunas os atributos e a última coluna a saída. Os 10 atributos referem-se à caracterização de amostras da fala de britânicos. A saída é o fonema de vogal correspondente, dentre as 11 possibilidades. Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/d/307."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl5YskAVLjlb"
   },
   "source": [
    "Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_ww82fALf9F"
   },
   "outputs": [],
   "source": [
    "dados_vowel = np.genfromtxt('./vowel.csv', delimiter = ',', skip_header = 0)\n",
    "np.set_printoptions()\n",
    "dados_vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzG2oNnjLpSS"
   },
   "outputs": [],
   "source": [
    "X = dados_vowel[:, 0:-1]\n",
    "y = dados_vowel[:, [-1]]\n",
    "print(\"Matriz de variáveis x:\")\n",
    "print(X, end = '\\n\\n')\n",
    "print(\"Vetor da variável y (primeiros elementos):\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zR7fhGP49jG"
   },
   "source": [
    "*One hot encoding* como representação da classe/rótulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-lofhTI5au_"
   },
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y)) # número de classes\n",
    "Y = np.zeros((y.shape[0], n_classes)) # inicializando a matriz Y com zeros\n",
    "for c in range(n_classes):\n",
    "  Y[:, [c]] = 1 * (y == c) # substituindo 0 por 1 na posição relacionada à classe de cada padrão\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3Hkp-GMIWHY"
   },
   "source": [
    "## a)\n",
    "Considere um modelo de classificação não linear baseado em redes neurais artificiais. Separe os dados aleatoriamente em treino, validação e teste (por exemplo, 60%, 20% e 20%). Nesse cenário, treine e avalie o modelo abaixo:\n",
    "- **MLP (multilayer perceptron)**: 1 camada oculta e treinamento em minibatch via gradiente descendente estocástico com termo de momentum. Utilize o conjunto de validação para ajustar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGw6QbYINx_m"
   },
   "source": [
    "Informações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VAFCcCANxOg"
   },
   "outputs": [],
   "source": [
    "n = X.shape[0] # tamanho da amostra original\n",
    "D = X.shape[1] # número de dimensões de entrada (atributos)\n",
    "K = Y.shape[1] # número de dimensões de saída (classes)\n",
    "n_treino = round(0.6*n) # tamanho da amostra de treino\n",
    "n_validacao = round(0.2*n) # tamanho da amostra de validação\n",
    "n_teste = n - n_treino - n_validacao # tamanho da amostra de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlnDjs3JjvlA"
   },
   "source": [
    "Busca pelos hiperparâmetros ótimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e480aw2Hjxqg"
   },
   "outputs": [],
   "source": [
    "# Divisão das amostras e normalização dos dados\n",
    "I = np.random.permutation(n) # permutação dos índices das observações\n",
    "(X_treino, X_validacao, X_teste) = (X[I][:n_treino,], X[I][n_treino:(n_treino + n_validacao),], X[I][(n - n_teste):,])\n",
    "(Y_treino, Y_validacao, Y_teste) = (Y[I][:n_treino,], Y[I][n_treino:(n_treino + n_validacao),], Y[I][(n - n_teste):,])\n",
    "\n",
    "X_treino = norm_min_max(X_treino, X_treino)\n",
    "X_validacao = norm_min_max(X_validacao, X_treino)\n",
    "X_teste = norm_min_max(X_teste, X_treino)\n",
    "\n",
    "X_validacao = np.c_[np.ones(n_validacao), X_validacao] # inserindo o termo de viés\n",
    "X_teste = np.c_[np.ones(n_teste), X_teste] # inserindo o termo de viés\n",
    "\n",
    "# Busca pelos hiperparâmetros ótimos\n",
    "n_iteracoes_hp = 1000 # número de iterações na busca pelos hiperparâmetros ótimos\n",
    "f_ativ_oculta = 'ReLU'\n",
    "f_ativ_saida = 'softmax'\n",
    "f_custo = 'entropia'\n",
    "\n",
    "custo_hp_min = np.inf # inicializando o custo mínimo de validação como infinito (para escolher melhor combinação de hiperparâmetros)\n",
    "for i in range(n_iteracoes_hp):\n",
    "  # Hiperparâmetros\n",
    "  alfa_0 = 10**np.random.uniform(-5, -1) # taxa de aprendizagem inicial\n",
    "  n_epocas = np.random.randint(200, 500) # número de épocas\n",
    "  momentum = np.random.uniform(0.5, 1) # termo de momentum\n",
    "  n_neuronios = np.random.randint(11, 200) # número de neurônios\n",
    "  B = np.random.randint(10, 100) # quantidade de padrões utilizados por mini-batch durante o treinamento\n",
    "  termo_reg = np.random.uniform(0.01, 0.1) # termo de regularização\n",
    "\n",
    "  # Etapa de treinamento e validação\n",
    "  rede_MLP = MLP_treino(X_treino, Y_treino, X_validacao, Y_validacao, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = True)\n",
    "  (W_hp, M_hp) = (rede_MLP[0], rede_MLP[1]) # matrizes de parâmetros associados ao melhor modelo para a combinação de hiperparâmetros da iteração atual\n",
    "\n",
    "  MLP_validacao = MLP_1co_direto(X_validacao, Y_validacao, W_hp, M_hp, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validação\n",
    "  custo_validacao = MLP_validacao[3] # custo de validação do melhor modelo\n",
    "\n",
    "  if custo_validacao < custo_hp_min:\n",
    "    custo_hp_min = custo_validacao\n",
    "    (W_melhor, M_melhor) = (W_hp, M_hp) # atualizando matrizes de parâmetros associados ao melhor modelo durante o treinamento/validação\n",
    "    (alfa_0_melhor, n_epocas_melhor, momentum_melhor, n_neuronios_melhor, B_melhor, termo_reg_melhor) = (alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg) # atualizando melhor combinação de hiperparâmetros\n",
    "    (custo_treino_it_melhor, custo_validacao_ep_melhor) = (rede_MLP[2], rede_MLP[3])\n",
    "\n",
    "plt.plot(custo_treino_it_melhor) # curva de aprendizagem de treino para a melhor combinação de hiperparâmetros\n",
    "plt.xlabel(\"Iteração\")\n",
    "plt.ylabel(\"Entropia cruzada\")\n",
    "plt.title(\"Treinamento via SGD com momentum\");\n",
    "\n",
    "print(\"Hiperparâmetros do melhor modelo:\")\n",
    "print(\"taxa de aprendizagem inicial: %.3f, número de épocas: %d, termo de momentum: %.2f, número de neurônios: %d, tamanho do mini-batch: %d e termo de regularização: %.2f\" % \n",
    "      (alfa_0_melhor, n_epocas_melhor, momentum_melhor, n_neuronios_melhor, B_melhor, termo_reg_melhor), end = '\\n\\n')\n",
    "\n",
    "# Etapa de teste (Generalização)\n",
    "MLP_teste = MLP_1co_direto(X_teste, Y_teste, W_melhor, M_melhor, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "custo_teste = MLP_teste[3] # entropia cruzada de teste\n",
    "print(\"Entropia cruzada de teste: %.4f\" % custo_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_y25T0urF0OE"
   },
   "source": [
    "Plotando a curva de aprendizagem de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "za-fqsfTF5sj"
   },
   "outputs": [],
   "source": [
    "plt.plot(custo_validacao_ep_melhor) # curva de aprendizagem de validação para a melhor combinação de hiperparâmetros\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Entropia cruzada\")\n",
    "plt.title(\"Validação\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOb6lfBKO0n_"
   },
   "source": [
    "Retreinamento com os dados de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWOh4FaRO10K"
   },
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "f_ativ_oculta = 'ReLU' # já que se trata de um problema de classificação\n",
    "f_ativ_saida = 'softmax' # já que se trata de um problema multiclasse\n",
    "f_custo = 'entropia' # já que se trata de um problema de classificação\n",
    "alfa_0 = alfa_0_melhor # taxa de aprendizagem inicial\n",
    "n_epocas = n_epocas_melhor # número de épocas\n",
    "momentum = momentum_melhor # termo de momentum\n",
    "n_neuronios = n_neuronios_melhor # número de neurônios\n",
    "B = B_melhor # quantidade de padrões utilizados por mini-batch durante o treinamento\n",
    "termo_reg = termo_reg_melhor # termo de regularização\n",
    "\n",
    "# Etapa de treinamento\n",
    "X_retreino = np.r_[X_treino, X_validacao[:, 1:]] # juntando dados de treino e validação\n",
    "Y_retreino = np.r_[Y_treino, Y_validacao] # juntando dados de treino e validação\n",
    "\n",
    "rede_MLP = MLP_treino(X_retreino, Y_retreino, None, None, f_ativ_oculta, f_ativ_saida, f_custo, alfa_0, n_epocas, momentum, n_neuronios, B, termo_reg, validacao = False)\n",
    "(W, M) = (rede_MLP[0], rede_MLP[1]) # matrizes de parâmetros da rede MLP retreinada\n",
    "\n",
    "plt.plot(rede_MLP[2]) # curva de aprendizagem de treino\n",
    "plt.xlabel(\"Iteração\")\n",
    "plt.ylabel(\"Entropia cruzada\")\n",
    "plt.title(\"Treinamento via SGD com momentum\");\n",
    "\n",
    "# Etapa de teste (Generalização)\n",
    "MLP_teste = MLP_1co_direto(X_teste, Y_teste, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "custo_teste = MLP_teste[3] # custo de teste\n",
    "print(\"Entropia cruzada de teste (normalizado): %.4f\" % custo_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kYP_hP2I_8T"
   },
   "source": [
    "## b)\n",
    "Apresente as curvas da função custo nos conjuntos de treinamento e validação ao longo das épocas. Reporte também a acurácia obtida para os conjuntos de treino, validação e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNXGqpOwT_B9"
   },
   "source": [
    "Curvas da função custo apresentadas no item a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcW7zv-_T_5m"
   },
   "outputs": [],
   "source": [
    "def acertos(Y, Y_pred): # retorna o número e a taxa de acertos (acurácia) gerais de classificação\n",
    "  n = Y.shape[0] # quantidade de padrões\n",
    "  n_acertos = 0\n",
    "  for i in range(n):\n",
    "    classe_pred = np.argmax(Y_pred[i,:])\n",
    "    if Y[i, classe_pred] == 1:\n",
    "      n_acertos += 1\n",
    "  p_acertos = n_acertos/n\n",
    "  return n_acertos, p_acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwzBIRZ-bXii"
   },
   "outputs": [],
   "source": [
    "X_treino_2 = np.c_[np.ones(n_treino), X_treino] # inserindo o termo de viés\n",
    "direto_treino = MLP_1co_direto(X_treino_2, Y_treino, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de treino\n",
    "Y_pred_treino = direto_treino[1] # valores preditos de treino\n",
    "acertos_treino = acertos(Y_treino, Y_pred_treino) # acertos de treino\n",
    "acertos_classe_treino = acertos_classe(Y_treino, Y_pred_treino) # acertos de treino por classe\n",
    "\n",
    "direto_validacao = MLP_1co_direto(X_validacao, Y_validacao, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de validação\n",
    "Y_pred_validacao = direto_validacao[1] # valores preditos de validação\n",
    "acertos_validacao = acertos(Y_validacao, Y_pred_validacao) # acertos de validação\n",
    "acertos_classe_validacao = acertos_classe(Y_validacao, Y_pred_validacao) # acertos de validação por classe\n",
    "\n",
    "direto_teste = MLP_1co_direto(X_teste, Y_teste, W, M, f_ativ_oculta, f_ativ_saida, f_custo) # sentido direto da rede MLP aplicado aos dados de teste\n",
    "Y_pred_teste = direto_teste[1] # valores preditos de teste\n",
    "acertos_teste = acertos(Y_teste, Y_pred_teste) # acertos de teste\n",
    "acertos_classe_teste = acertos_classe(Y_teste, Y_pred_teste) # acertos de teste por classe\n",
    "\n",
    "print(\"Acurácia de treino, validação e teste: %.2f%%, %.2f%% e %.2f%%\" % (100*acertos_treino[1], 100*acertos_validacao[1], 100*acertos_teste[1]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Alessandro_AMA_Lista3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
